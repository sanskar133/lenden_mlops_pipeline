{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "07a47969-6092-4f53-a178-7e34490eaaee",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%pip install databricks-feature_engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ed604cff-d386-4ed9-9b88-e14e988ec706",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%pip install lightgbm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c87675be-4355-4ae1-aabd-d38b5c9f9fca",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%restart_python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "77f826bb-b403-4214-a5ab-fb3a00a1f5f8",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# **Model Logging**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "6e11a365-a81a-4a2e-998a-de86d5a4b3fc",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### 1.will create input ,output signature to register model in unity catalog\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "f36a4702-cc05-4583-a80f-f9fef8ffe542",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### 2. Save features used by model as json in folder artifacts to correctly match features no mismatch happen during inferencing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "d1ee8e88-878a-4812-9000-57bc7affc634",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### 3. create a custom wrapper class to control how the model is loaded, how inputs are processed, and how predictions are madeâ€”independent of how the model was originally trained. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "ea8ff93e-b7de-4400-b5ac-c7368346e178",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### 4.then log that class to unity catalog table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b1df6560-a382-46c0-9e2d-d178a5d0110b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "import pickle\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import lightgbm as lgb\n",
    "import joblib\n",
    "from datetime import datetime, date\n",
    "import mlflow\n",
    "import mlflow.lightgbm\n",
    "from sklearn.metrics import classification_report,roc_auc_score,f1_score\n",
    "from mlflow.models.signature import infer_signature\n",
    "from databricks.feature_engineering import FeatureEngineeringClient\n",
    "from databricks.feature_engineering import FeatureEngineeringClient, FeatureLookup\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import json\n",
    "import requests\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "from pyspark.sql.functions import col"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "70968817-66bd-4e52-817b-ad6a0e6fa556",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## INFER SIGNATURE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "7ae7f338-b4ed-4ce5-9a8a-14777a6f6493",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "The signature is used for:\n",
    "\n",
    "Model Serving input validation\n",
    "\n",
    "Batch inference validation\n",
    "\n",
    "Feature mismatch protection\n",
    "\n",
    "Safe model upgrades\n",
    "\n",
    "Automated governance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "913cb182-f723-4837-8b24-b87d1cdd424e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### first we load a sample training dataset using feature stores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "9ad0f965-45ad-4f81-be1b-0914b50153c2",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### then we load the features use by model using model.input_features_names_ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "728790e7-4166-41e3-99df-4672e6bb156a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### then we create the dataframe with those features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "7306a182-aa36-4216-a317-7aabd21b316d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### create signature using that input feature dataframe and output predicted using model on that dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "72616f83-0ecd-4bdf-a650-f52e7090564d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "we are using table that we created in preprocessing stages just to get label ,target so to create spark label dataframe to featch training features using loan_id,target variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5f89d35d-262b-4226-97d8-dfd4bac86a54",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Load the base Spark table containing training data\n",
    "# This table typically includes loan_id and target label\n",
    "base_4 = spark.table('ispl_databricks.model_logs.bd_500_features_sample_training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ca9bc0c8-766d-4795-8525-b9e8b5a4994e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Select only the primary key (loan_id) and target column\n",
    "# This DataFrame will act as the label dataset\n",
    "spark_label =  base_4.select(col('loan_id'),col('target'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ae729762-61b3-4bcb-9253-52707cba5656",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "fe = FeatureEngineeringClient()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "236f4fb0-ffac-4cc2-921e-f433ee8ea227",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Create a Feature Store training set\n",
    "# This joins labels with features using loan_id as the lookup key\n",
    "training_set = fe.create_training_set(\n",
    "    df=spark_label,\n",
    "    feature_lookups=[\n",
    "        FeatureLookup(\n",
    "            table_name=\"ispl_databricks.model_logs.bd_final_feature_stores\",\n",
    "            lookup_key=\"loan_id\"\n",
    "        )\n",
    "    ],\n",
    "    label=\"target\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4a2fe77d-f1f4-413d-bf83-1379969350a6",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#since what we got is an spark dataframe but to log we have to convert pandas dataframe\n",
    "train_pd = training_set.load_df().toPandas()\n",
    "train_pd = train_pd.dropna()\n",
    "#dropping loan_id,target from train_x\n",
    "train_x  = train_pd.drop(['loan_id','target'], axis=1)\n",
    "#selecting target variable for train_Y\n",
    "train_y = train_pd['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f39fc3e2-0668-4651-b623-d27cd038f105",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# taking a a single row dataframe for input_X to create model signature\n",
    "input_X = train_x.iloc[[0]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "968175fa-7496-4fbf-a577-a0a97862dab0",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "loading model to featch features used by model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "358a0307-e491-4e86-bce6-7a5e2a08833c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "# Load a pre-trained model from Databricks workspace using joblib\n",
    "# This model was previously trained (e.g., on top 50 features)\n",
    "model = joblib.load('/Workspace/Shared/ff_bd/model_artifacts/top50model.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "faa5f005-e656-4a51-8e28-5f4576968f09",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# get features names that model uses for inference saving those features to a json so that while logging model there are no mismatch and we can get features that were used by model as in light_bgm sometime model pass and model it take for training changes\n",
    "trained_feature_names = model.feature_name_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "73dbeb82-21eb-47c8-a69b-863ee9d56124",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "len(trained_feature_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0e059ea0-70b1-4cc4-94ed-da3ce86f5c21",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# creating feature json will dump in model artifact folder so that while creating custom wrapper class we can get features that were used by model\n",
    "feature_json = {'features': trained_feature_names}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e8874754-df74-451d-a7e5-6f18c13d1f97",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#dumping the json\n",
    "with open('/Workspace/Shared/ff_bd/model_artifacts/model_features.json','w') as f:\n",
    "    json.dump(feature_json, f, ensure_ascii=False, indent=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "8fe5aff5-ebe5-42e3-b4a4-fbaeb3f198da",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### infer signature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0f082438-8619-4c3b-86f2-58ad2a59712e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# creating model signature \n",
    "# Align input features to exactly match the features used during training\n",
    "# This avoids feature mismatch issues during inference\n",
    "input_X_aligned = input_X[trained_feature_names]\n",
    "# Generate model predictions (probability scores instead of class labels)\n",
    "# predict_proba is commonly used for classification models\n",
    "output = model.predict_proba(input_X_aligned)\n",
    "# Infer the MLflow model signature automatically\n",
    "# The signature captures:\n",
    "#  - Input schema (feature names + data types)\n",
    "#  - Output schema (prediction shape + types)\n",
    "# This is critical for model serving and validation\n",
    "signature = infer_signature(input_X_aligned, output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1e22c1e7-44d7-428b-9ec5-a59dea16c244",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "with open('/Workspace/Shared/ff_bd/model_artifacts/model_features.json') as file:\n",
    "    data = json.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8d1be796-4272-40e8-9e11-c06b48e206b3",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "24b4c455-910a-4c07-8111-c8f88689c55c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### final model logging"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "de3253f1-61c8-4e06-8e6e-9f366d0d45dc",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "creating custom wrapper class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "77b06889-5bf0-4aab-96e5-7df4886a22cf",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Custom MLflow PyFunc wrapper for model loading and inference\n",
    "# This allows the model to be served in a standardized way\n",
    "class mlwrapper(mlflow.pyfunc.PythonModel):\n",
    "     # Load the trained model artifact at model serving / inference time\n",
    "    def load_context(self,context):\\\n",
    "        # load model from model artifact folder\n",
    "        self.model = joblib.load(context.artifacts['model_artifacts']+'/top50model.pkl')\n",
    "        # Load feature metadata used during training\n",
    "        # This ensures feature consistency during inference\n",
    "        with open(context.artifacts['model_artifacts']+'/model_features.json', 'r') as file:\n",
    "            data = json.load(file)\n",
    "        \n",
    "        # Store the list of trained feature columns\n",
    "        self.fc = data['features']\n",
    "        print(self.fc)\n",
    "        \n",
    "    def predict(self,context,model_input):\n",
    "\n",
    "        # Align incoming inference data with trained feature columns\n",
    "        # This prevents feature mismatch issues\n",
    "        df = model_input[self.fc]\n",
    "        # Return class probability predictions\n",
    "        return self.model.predict_proba(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "81cfc91a-bb2d-4d31-bbc6-084c39ea93dd",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "running mlflow experiment and registering model into unity catalog"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b6030eb2-af29-4907-bdf2-c33d7f9fde0a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "with mlflow.start_run():\n",
    "\n",
    "    # Log evaluation metric for the trained model\n",
    "    mlflow.log_metric(\"test_accuracy\", metric['accuracy'])\n",
    "\n",
    "    # Log the model using MLflow PyFunc format\n",
    "    # This makes the model deployable via MLflow Model Serving\n",
    "    mlflow.pyfunc.log_model(\n",
    "        artifact_path=\"model\",\n",
    "        python_model=mlwrapper(),\n",
    "        artifacts={\"model_artifacts\": \"/Workspace/Shared/ff_bd/model_artifacts\"},\n",
    "        registered_model_name=\"ispl_databricks.model_logs.final_bd_model\",\n",
    "        signature=signature\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "56175a7d-1faa-4852-abf6-ec2704d7b2ab",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### fetching latest model version doing inference on it to test whether model logged succesddfully or not"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5d43a34d-0c9e-407b-92f6-03a2329fa1f2",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "# fetching latest version of model\n",
    "from mlflow.tracking import MlflowClient\n",
    "client = MlflowClient()\n",
    "versions = client.search_model_versions(\"name = 'ispl_databricks.model_logs.final_bd_model'\")\n",
    "\n",
    "latest_version = sorted(versions, key=lambda v: int(v.version))[-1].version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c3a77a42-03e7-4855-8da4-256445863a90",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# uri of latest model\n",
    "model_uri = f\"models:/ispl_databricks.model_logs.final_bd_model/{latest_version}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "31e581f0-0bf9-4bc4-8b3b-a1db6fff5a40",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# load latest model\n",
    "model = mlflow.pyfunc.load_model(model_uri=model_uri)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "fa2a4b4f-2194-482c-9421-c2d11d02538e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# make prediction using latest model\n",
    "model.predict(input_X_aligned)"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "4"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "model_logging",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
