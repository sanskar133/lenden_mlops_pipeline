{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4459fd71-9e81-40aa-a1be-b346dce4d674",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "pip install lightgbm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "95e2b11e-5b6d-41d5-ba05-bb5ca436a4a0",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "pip install hyperopt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "43b3d334-9214-4b25-b6af-e454bec48ff6",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%pip install databricks-feature_engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "872a2575-6467-4395-b56e-04b61fdd1ea0",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    " %restart_python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "fbbf4708-3929-4e5f-8a9c-2265843c0943",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import lightgbm as lgb\n",
    "import pickle\n",
    "import joblib\n",
    "import os\n",
    "from datetime import datetime, date \n",
    "from sklearn.model_selection import train_test_split\n",
    "import mlflow\n",
    "import mlflow.lightgbm\n",
    "from sklearn.metrics import classification_report,roc_auc_score,f1_score\n",
    "import numpy as np\n",
    "from mlflow.models.signature import infer_signature\n",
    "from hyperopt import fmin, tpe, hp, Trials, STATUS_OK\n",
    "from hyperopt.pyll import scope\n",
    "import numpy as np\n",
    "from hyperopt import fmin, tpe, hp, Trials, STATUS_OK\n",
    "from hyperopt.pyll import scope\n",
    "from databricks.feature_engineering import FeatureEngineeringClient\n",
    "from databricks.feature_engineering import FeatureEngineeringClient, FeatureLookup\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import json\n",
    "from mlflow.tracking import MlflowClient\n",
    "import requests\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "3443ffe7-e564-4812-a0b0-ff682559c02b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "in this notebbok we will load fetaures from feature store create training set with it\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f3454e09-2d1f-4d83-a52a-dfeefb6bfdb6",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "train the model with hyperopt experiments with 30 trials \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "322a60b9-29dc-4c1d-9c20-2d3a99fb8ed8",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "logged the best parameter all other trials as child run under it\n",
    "final save the model with best parameter registered in unity catalog"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "f43df7ba-beab-45c7-a199-dd72080f17dd",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "93e1eff5-b651-4e75-a827-5f91219cd1ef",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### creating training dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b6cedf00-17e8-495c-969d-5c93fc2befd0",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# we loading the delta table that we had saved in preprocessing notebook\n",
    "base_4 = spark.table(\"ispl_databricks.model_logs.bd_500_features_sample_training\").toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "cff7882e-a4d7-456a-a9ca-f7a0f91b8ed3",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "base_4.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c431c6ae-4c9a-425c-9093-4e055bf8b513",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "base_4['type'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "92231488-aaf5-41c7-97f8-5523a8024c88",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "creating label dataframe consist of target and loan_id it will used fetch features for corresponding laon_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3e107c33-bdaf-4341-b9f3-86463a39a421",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "# we are creating spark dataframe loan_id,target to create a label dataframe for creating training data set using feautre store\n",
    "spark_label =  spark.createDataFrame(base_4[['loan_id','target']])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "11ecb319-2031-43d2-84bf-d3edf5b4d059",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Split the dataset into training and validation sets based on the 'type' column\n",
    "input_final_df_train=base_4[base_4['type']=='training']\n",
    "live_input_final_df=base_4[base_4['type']=='validation']\n",
    "\n",
    "# Create a standardized label column ('actual_label') for model training and evaluation\n",
    "# by copying values from the existing target column\n",
    "input_final_df_train[\"actual_label\"] = input_final_df_train[\"target\"]\n",
    "live_input_final_df[\"actual_label\"] = live_input_final_df[\"target\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "dcb831ae-cf28-4884-9b7e-6f5775a5e891",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "input_final_df_train['actual_label'].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "dcdd4fc1-e726-4247-b101-5d0d69e2e6f1",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "live_input_final_df['actual_label'].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3d4dcea3-d004-4ff9-ac4a-e329aa150a56",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "live_input_final_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "541006ce-e49f-46a1-a0c6-3e4cf12fb50f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "creating (loan_id,target) dataset for training and test "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d562921c-c64e-4cfa-a303-40cd43cdc2ab",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#loading train and test data\n",
    "train_data = base_4[base_4['type'] == 'training'].copy()\n",
    "test_data = base_4[base_4['type'] == 'validation'].copy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "014d9b1a-e71b-4673-9fd6-faa11a181005",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#creating label dataframe for training and test data\n",
    "train_data = train_data[['target','loan_id']]\n",
    "test_data = test_data[['target','loan_id']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "73c7e1eb-e873-45a9-b181-7703d302efe7",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# creating a spark label dataframe for spark_train_label,spark_test_label\n",
    "spark_train_label = spark.createDataFrame(train_data)\n",
    "spark_test_label = spark.createDataFrame(test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "a0a32a89-e4a8-4610-8fc5-de73313b5b64",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### creating train and test dataset using features store with the help of (loan_id,target) data frame corresponding to them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d314b78b-f7b0-4c92-a46a-d7df214fc999",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "fe = FeatureEngineeringClient()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5461dfba-1a0f-412b-ad7f-2d61e5a0f2c2",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#loading features for training data using spark training label dataframe and loan_id\n",
    "training_set = fe.create_training_set(\n",
    "    df=spark_train_label,\n",
    "    feature_lookups=[\n",
    "        FeatureLookup(\n",
    "            table_name=\"ispl_databricks.model_logs.bd_500_features_store_training\",\n",
    "            lookup_key=\"loan_id\"\n",
    "        )\n",
    "    ],\n",
    "    label=\"target\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "09927713-6954-4b8f-98c3-3aae6df4fc80",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#creating x_train and y_train\n",
    "train_pd = training_set.load_df().toPandas()\n",
    "X_train = train_pd.drop(['loan_id','target'], axis=1)\n",
    "y_train = train_pd['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c1f0512e-cb09-4bb6-beaa-39092a9509e3",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "#loading features for test data using spark test label dataframe and loan_id\n",
    "test_set = fe.create_training_set(\n",
    "    df=spark_test_label,\n",
    "    feature_lookups=[\n",
    "        FeatureLookup(\n",
    "            table_name=\"ispl_databricks.model_logs.bd_500_features_store_training\",\n",
    "            lookup_key=\"loan_id\"\n",
    "        )\n",
    "    ],\n",
    "    label=\"target\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "739a3529-580b-4ddc-a449-c7678234940a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#creating X_test,y_test\n",
    "test_pd = test_set.load_df().toPandas()\n",
    "X_test = test_pd.drop(['loan_id','target'], axis=1)\n",
    "y_test = test_pd['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c162234f-ada5-4c24-9bfd-4f439455c7ee",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d0f78ad9-b131-4821-aaff-228049835ecd",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "e1d83da9-7ba8-4974-9d7b-d743f3132cd0",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "creating folder save models ,features and columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ce2ee8f2-d744-4ec3-94df-865b45b7b70f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "model_trainYN = 1\n",
    "data_version = \"base\"\n",
    "\n",
    "input_dir = \"/Volumes/ispl_databricks/default/training/ff_bd/input_dir\"\n",
    "output_dir = \"/Volumes/ispl_databricks/default/training/ff_bd/output_dir_same_columns\"\n",
    "model_dir = \"/Volumes/ispl_databricks/default/training/ff_bd/model_dir\"\n",
    "\n",
    "# Set data version\n",
    "data_version = os.path.join(\"base\")   # change here\n",
    "# data_version = os.path.join(\"data_v5_new/top_20\")   # alternative version\n",
    "\n",
    "# Version-specific directories\n",
    "input_dir_version = os.path.join(input_dir, data_version)\n",
    "output_dir_version = os.path.join(output_dir, data_version)\n",
    "model_dir_version = os.path.join(model_dir, data_version)\n",
    "\n",
    "# Create directories if they do not exist\n",
    "for directory in [output_dir_version, model_dir_version]:\n",
    "    os.makedirs(directory, exist_ok=True)\n",
    "\n",
    "# Model and feature file names\n",
    "model_file_name = \"lgb_model.pickle\"\n",
    "feature_file_name = \"model_input_feature.pickle\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "e0666bc9-d27c-4b41-a636-3f53cd26bf02",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### hyperopt experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "351913c5-0c7c-4a82-a27b-f41b37848763",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "# Set MLflow experiment\n",
    "mlflow.set_experiment(\"/Workspace/Shared/ff_bd/FF_bd_lgbm_all_columns_experiment\")\n",
    "\n",
    "# Train or load LGBMClassifier\n",
    "if model_trainYN == 1:\n",
    "    with mlflow.start_run(run_name=f\"LGBM_{data_version}\") as run:\n",
    "\n",
    "        # -----------------------------\n",
    "        # Hyperparameter tuning section\n",
    "        # -----------------------------\n",
    "        search_space = {\n",
    "            'num_leaves': scope.int(hp.quniform('num_leaves', 20, 150, 1)),\n",
    "            'max_depth': scope.int(hp.quniform('max_depth', 3, 15, 1)),\n",
    "            'learning_rate': hp.uniform('learning_rate', 0.01, 0.3),\n",
    "            'n_estimators': scope.int(hp.quniform('n_estimators', 100, 800, 50)),\n",
    "            'min_child_samples': scope.int(hp.quniform('min_child_samples', 10, 100, 5)),\n",
    "            'subsample': hp.uniform('subsample', 0.6, 1.0),\n",
    "            'colsample_bytree': hp.uniform('colsample_bytree', 0.6, 1.0)\n",
    "        }\n",
    "\n",
    "        def objective(params):\n",
    "            # logging all trials under parent trial that is best parameter trial ith trial_id\n",
    "            trial_id = len(trials.trials)\n",
    "            with mlflow.start_run(run_name=f\"trial_{trial_id}_LGBM\",nested=True):\n",
    "                model = lgb.LGBMClassifier(\n",
    "                random_state=42,\n",
    "                class_weight='balanced',\n",
    "                **params\n",
    "            )\n",
    "                model.fit(\n",
    "                    X_train, y_train,\n",
    "                    eval_set=[(X_test, y_test)],\n",
    "                    eval_metric=\"binary_logloss\"\n",
    "            )\n",
    "                val_pred_proba = model.predict_proba(X_test)[:, 1]\n",
    "                val_logloss = -((y_test * np.log(val_pred_proba) + (1 - y_test) * np.log(1 - val_pred_proba)).mean())\n",
    "                acccuracy = accuracy_score(y_test, model.predict(X_test))\n",
    "                mlflow.log_metric(\"val_logloss\", val_logloss)\n",
    "                mlflow.log_metric(\"accuracy\", acccuracy)   \n",
    "                mlflow.log_params(params) \n",
    "                return {'loss': val_logloss, 'status': STATUS_OK}\n",
    "\n",
    "        trials = Trials()\n",
    "        best_params = fmin(\n",
    "            fn=objective,\n",
    "            space=search_space,\n",
    "            algo=tpe.suggest,\n",
    "            max_evals=30,\n",
    "            trials=trials,\n",
    "            rstate=np.random.default_rng(42)\n",
    "        )\n",
    "\n",
    "        # Convert integer-like floats back to ints\n",
    "        best_params = {\n",
    "            k: int(v) if isinstance(v, float) and v.is_integer() else v\n",
    "            for k, v in best_params.items()\n",
    "        }\n",
    "\n",
    "        mlflow.log_params(best_params)\n",
    "        mlflow.log_param(\"class_weight\", \"balanced\")\n",
    "        mlflow.log_param(\"random_state\", 42)\n",
    "\n",
    "\n",
    "        # -----------------------------\n",
    "        # Train final model with best params\n",
    "        # -----------------------------\n",
    "        model = lgb.LGBMClassifier(\n",
    "            random_state=42,\n",
    "            class_weight='balanced',\n",
    "            **best_params\n",
    "        )\n",
    "\n",
    "        model = model.fit(\n",
    "            X_train,\n",
    "            y_train,\n",
    "            eval_set=[(X_train, y_train), (X_test, y_test)],\n",
    "            eval_names=[\"train\", \"valid\"],\n",
    "            eval_metric=[\"binary_logloss\"]\n",
    "        )\n",
    "\n",
    "        # Infer model signature from training data and predictions\n",
    "    \n",
    "\n",
    "        # Save the trained model locally\n",
    "        pickle.dump(\n",
    "            model,\n",
    "            open(os.path.join(output_dir_version, model_file_name), \"wb\")\n",
    "        )\n",
    "        joblib.dump(model, os.path.join(output_dir_version, \"job_model.pkl\"))\n",
    "\n",
    "        # Save input feature list\n",
    "        input_feature_model = X_train.columns.tolist()\n",
    "        pickle.dump(\n",
    "            input_feature_model,\n",
    "            open(os.path.join(output_dir_version, feature_file_name), \"wb\")\n",
    "        )\n",
    "        mlflow.log_artifact(os.path.join(output_dir_version, feature_file_name))\n",
    "\n",
    "        # Log some metrics (example)\n",
    "        y_pred = model.predict(X_test)\n",
    "        accuracy = (y_pred == y_test).mean()\n",
    "        mlflow.log_metric(\"accuracy\", accuracy)\n",
    "\n",
    "else:\n",
    "    # Load pre-trained model\n",
    "    model = pickle.load(open(os.path.join(output_dir_version, model_file_name), \"rb\"))\n",
    "    model = joblib.load(os.path.join(output_dir_version, \"job_model.pkl\"))\n",
    "\n",
    "    # Load input feature list\n",
    "    input_feature_model = pickle.load(\n",
    "        open(os.path.join(output_dir_version, feature_file_name), \"rb\")\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "5d7231da-e249-4871-8420-c8779ecdbaea",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### saving model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4cb6f4f9-9c16-4916-8c28-02fef3c29345",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# dumping model at specific path to make it reusable\n",
    "pickle.dump(\n",
    "            model,\n",
    "            open(os.path.join(output_dir_version, model_file_name), \"wb\")\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d55bf188-8e50-4978-9ecd-9c03be07d0d8",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# loading the model that  save \n",
    "model = pickle.load(open(os.path.join(output_dir_version, model_file_name), \"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "818601e2-0a9d-477f-8056-333efc84d183",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#dumping model into model artifacts folder so that it can be easily in unity catalog\n",
    "joblib.dump(model,'/Workspace/Shared/ff_bd/model_artifacts/500features.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "dedd6369-cde8-4475-b37f-3b5864970f78",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#loading model\n",
    "model =  joblib.load('/Workspace/Shared/ff_bd/model_artifacts/500features.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "6cb9746a-bf45-4d5a-a329-7dc87924f7d0",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## ### model registary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "5be5f8bb-87a3-4f93-8e40-16508edc33cc",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### defining signature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "dc7caa6e-87b7-4e44-bc26-ae339e6bfccb",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#getting features used in model while training or the features on which model trained this prevents the schema mismatch while loggong into mlflow or while inferencing\n",
    "training_features = model.feature_name_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e67f5f63-073f-415f-962a-0e50bf619da4",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# defing an input_x as a dataframe for example or defining signature\n",
    "input_x = X_train[training_features].iloc[[1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "96e09b24-e169-4835-97a6-0c5d4ebf665f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# input_y for signature of output\n",
    "input_y  = model.predict(input_x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "844e6ae5-3dc0-4cd7-a0c5-eceefd663fb6",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# defining  signature  as it required while logging in mlflow as it prevent schema mismatch\n",
    "signature = infer_signature(input_x, input_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "a1b85a6a-8186-42da-8f15-8054a07c1988",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "creating custom wrapper class to simplyfy registary and inferencing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b32f23ab-30e9-4248-9fd0-7261905e4f18",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#This custom MLflow PyFunc wrapper loads the trained model and its feature list, ensures schema consistency at inference time, and returns probability predictions for downstream evaluation or deployment it make easy to log the model into ml flow prevents schema mismatch.\n",
    "class mlwrapper(mlflow.pyfunc.PythonModel):\n",
    "    def load_context(self,context):\n",
    "        #loading model that we had saved in artifacts\n",
    "        self.model = joblib.load(context.artifacts['model_artifacts']+'/500features.pkl')\n",
    "        #loading features used in model\n",
    "        self.fc = model.feature_name_\n",
    "        print(self.fc)\n",
    "        \n",
    "    def predict(self,context,model_input):\n",
    "        df = model_input[self.fc]\n",
    "        return self.model.predict_proba(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "a2bdd8ad-2ddc-4661-9fa3-4f42963eee4b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "registering model into unity catalog wit mlflow experiment also logging accuracy of model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8a1ef2f1-7fa3-4a80-b5a9-93e2f11cbc58",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Log the trained model to Unity Catalog using MLflow Model Registry\n",
    "# Catalog  : ispl_databricks\n",
    "# Schema   : model_logs\n",
    "# Model    : ffbd_lgbm_all_columns_endpoint\n",
    "# This enables centralized model governance, versioning, and deployment\n",
    "with mlflow.start_run():\n",
    "    # Log evaluation metric for model performance tracking\n",
    "    mlflow.log_metric(\"test_accuracy\", accuracy)\n",
    "\n",
    "    \n",
    "    # Log the trained model using a custom MLflow PyFunc wrapper\n",
    "    # The wrapper ensures consistent feature selection and inference logic\n",
    "    mlflow.pyfunc.log_model(\n",
    "        artifact_path=\"model\",\n",
    "        python_model=mlwrapper(),\n",
    "        # Path to model artifacts (e.g., serialized model files)\n",
    "        artifacts={\"model_artifacts\": \"/Workspace/Shared/ff_bd/model_artifacts\"},\n",
    "        # Register the model in Unity Catalog for lifecycle management\n",
    "        registered_model_name=\"ispl_databricks.model_logs.ffbd_lgbm_all_columns_endpoint\",\n",
    "        # Attach model signature to enforce input/output schema validation\n",
    "        signature=signature\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9cba5e18-6ea9-4201-bc99-68d6cff052bb",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "len(training_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ad71b2c7-37b6-4bc3-8708-79e6a1adfabd",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "lgb.plot_importance(model,max_num_features=30)\n",
    "\n",
    "### training evaluation\n",
    "lgb.plot_metric(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "c68d631d-05b1-492f-ab79-595965389405",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### inferencing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "55f6be4b-525d-48a4-8a0e-c812a5d86b27",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#model_name\n",
    "model_name_500 = 'ispl_databricks.model_logs.ffbd_lgbm_all_columns_endpoint'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "23b89197-b06f-4c97-a827-c550d36482be",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#loading versions of model\n",
    "client =MlflowClient()\n",
    "version500 = client.search_model_versions(f\"name='{model_name_500}'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "40eda3df-b19e-4d54-9895-e80d5770f819",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# fetching latest version of model\n",
    "latest_version500 = str(\n",
    "    sorted(\n",
    "        [int(versions.version) for versions in version500],\n",
    "        reverse=True\n",
    "    )[0]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "46e0992d-12c5-4444-8c06-86494e89a125",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#defining model_uri for latest model\n",
    "model_uri = f\"models:/ispl_databricks.model_logs.ffbd_lgbm_all_columns_endpoint/{latest_version500}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "636faf37-a4d1-4cff-b503-efdf45e815ab",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#loading latest model\n",
    "model = mlflow.pyfunc.load_model(model_uri)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "bae035d1-7750-4018-bfd4-c9af2627eed0",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# doing prediction on input_x\n",
    "model.predict(input_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "30ad7a17-79be-429c-a0c9-a7d66b51ac12",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "!pip freeze"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "4"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "training_all_features",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
