{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b1c48824-6871-4da9-a80b-cd334947e6f8",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "pip install lightgbm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "51f9dfe8-51e3-431e-9fef-dc5c7aec1678",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "pip install hyperopt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "bbcc67e7-71ee-4533-9246-d89091b3a903",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%pip install databricks-feature_engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ca61e020-c78a-4aab-a14a-bf1db462694c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "\n",
    " %restart_python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c195e984-a859-44cd-9e88-6619084463ed",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "import pickle\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import lightgbm as lgb\n",
    "import joblib\n",
    "from datetime import datetime, date\n",
    "import mlflow\n",
    "import mlflow.lightgbm\n",
    "from sklearn.metrics import classification_report,roc_auc_score,f1_score\n",
    "from mlflow.models.signature import infer_signature\n",
    "from hyperopt import fmin, tpe, hp, Trials, STATUS_OK\n",
    "from hyperopt.pyll.base import scope\n",
    "from databricks.feature_engineering import FeatureEngineeringClient\n",
    "from databricks.feature_engineering import FeatureEngineeringClient, FeatureLookup\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import json\n",
    "import requests\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "980c40a4-737c-4d72-8c16-7a9e44e11119",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "dbutils.widgets.text(\"training_csv\", \"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1b82640e-79b7-4c4a-8230-1399ab2dc4dc",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "input_path = dbutils.widgets.get(\"training_csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "38eb854b-59b9-4472-970e-87008b4ec05e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(input_path)\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f9578123-255b-486d-aca8-8d84ac844fcb",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Convert object columns to category\n",
    "for col in df.select_dtypes(include='object').columns:\n",
    "    df[col] = df[col].astype('category')\n",
    "\n",
    "# Convert dates\n",
    "df['status_date'] = pd.to_datetime(df['lr_created_date'], errors='coerce')\n",
    "\n",
    "# Create month-year column\n",
    "df['month_year'] = df['status_date'].dt.strftime('%m-%Y')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c763b2f0-6e90-4ff8-a278-ab3cd76ed968",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def assign_type(date):\n",
    "    if pd.Timestamp('2023-06-01') <= date < pd.Timestamp('2024-10-01'):\n",
    "        return 'train'\n",
    "    elif pd.Timestamp('2024-10-01') <= date < pd.Timestamp('2024-11-01'):\n",
    "        return 'test'\n",
    "    elif pd.Timestamp('2024-11-01') <= date < pd.Timestamp('2024-12-01'):\n",
    "        return 'live'\n",
    "    else:\n",
    "        return 'delete'\n",
    "\n",
    "df['type'] = df['status_date'].apply(assign_type)\n",
    "\n",
    "# Show counts\n",
    "print(df['type'].value_counts())\n",
    "\n",
    "# Filter and save datasets\n",
    "save_path = \"/Volumes/ispl_databricks/default/training/MW_Train/\"  # Databricks-compatible path\n",
    "\n",
    "# for dataset_type in ['train', 'test', 'live']:\n",
    "#     subset = df[df['type'] == dataset_type]\n",
    "#     subset.to_csv(f\"{save_path}{dataset_type}.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d62df614-2c87-4d4e-a417-dcd7a78741c6",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Create monthwise distribution visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Create a monthwise breakdown\n",
    "df['year_month'] = df['status_date'].dt.to_period('M')\n",
    "\n",
    "# Get monthwise distribution by type\n",
    "monthly_dist = df.groupby(['year_month', 'type']).size().unstack(fill_value=0)\n",
    "\n",
    "# Create the visualization\n",
    "plt.figure(figsize=(15, 8))\n",
    "\n",
    "# Plot stacked bar chart\n",
    "monthly_dist.plot(kind='bar', stacked=True, figsize=(15, 8), \n",
    "                  color=['#1f77b4', '#ff7f0e', '#2ca02c'])  # Blue, Orange, Green\n",
    "\n",
    "plt.title('Monthwise Distribution of Train, Test, and Live Data', fontsize=16, fontweight='bold')\n",
    "plt.xlabel('Month-Year', fontsize=12)\n",
    "plt.ylabel('Number of Records', fontsize=12)\n",
    "plt.legend(title='Data Type', bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "plt.xticks(rotation=45)\n",
    "plt.grid(axis='y', alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Print detailed monthwise breakdown\n",
    "print(\"Monthwise Distribution:\")\n",
    "print(\"=\" * 50)\n",
    "print(monthly_dist)\n",
    "print(\"\\n\" + \"=\" * 50)\n",
    "\n",
    "# Print summary statistics\n",
    "print(\"\\nSummary Statistics:\")\n",
    "print(f\"Total records: {len(df):,}\")\n",
    "print(f\"Date range: {df['status_date'].min()} to {df['status_date'].max()}\")\n",
    "print(f\"Train data: {len(df[df['type'] == 'train']):,} records\")\n",
    "print(f\"Test data: {len(df[df['type'] == 'test']):,} records\") \n",
    "print(f\"Live data: {len(df[df['type'] == 'live']):,} records\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "14def9cb-7438-4c92-a5a1-04569386e26d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Create a copy of the dataframe\n",
    "final = df.copy()\n",
    "\n",
    "\n",
    "# Convert '_is_' and '_exist' columns to category\n",
    "is_columns = [col for col in final.columns if '_is_' in col]\n",
    "exist_columns = [col for col in final.columns if col.endswith('_exist')]\n",
    "cat_columns = list(set(is_columns + exist_columns))  # combine lists\n",
    "\n",
    "# Convert all categorical columns at once\n",
    "final[cat_columns] = final[cat_columns].astype('category')\n",
    "print(f\"Number of categorical columns converted: {len(cat_columns)}\")\n",
    "\n",
    "\n",
    "# Replace common boolean/string values\n",
    "replace_dict = {\n",
    "    \"true\": 1, \"TRUE\": 1, True: 1,\n",
    "    \"false\": 0, \"FALSE\": 0, False: 0,\n",
    "    \"na\": np.nan,\n",
    "    \"error\": np.nan\n",
    "}\n",
    "\n",
    "final.replace(replace_dict, inplace=True)\n",
    "\n",
    "\n",
    "# Optional: Custom mapping for specific columns (example)\n",
    "# Example for a column like whatsapp_is_business\n",
    "# final['s3m_phone_data_primary_data_whatsapp_is_business'] = final['s3m_phone_data_primary_data_whatsapp_is_business'].map(\n",
    "#     lambda x: 1 if str(x) in ['1', '1.0'] else (0 if str(x) in ['0', '0.0'] else x)\n",
    "# )\n",
    "\n",
    "\n",
    "# Verify changes\n",
    "print(final[cat_columns].head())\n",
    "print(final[cat_columns].dtypes.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "88ac0ad4-49c2-4a7a-9ca7-eab4e815c40d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def calculate_age(dob_str):\n",
    "    \"\"\"Calculate age from DD-MM-YYYY string. Returns -1 if invalid or <18.\"\"\"\n",
    "    if pd.isna(dob_str):\n",
    "        return -1\n",
    "    try:\n",
    "        born = datetime.strptime(str(dob_str), \"%d-%m-%Y\").date()\n",
    "        today = date.today()\n",
    "        age = today.year - born.year - ((today.month, today.day) < (born.month, born.day))\n",
    "        return age if age >= 18 else -1\n",
    "    except Exception:\n",
    "        return -1\n",
    "\n",
    "# Apply function vectorized\n",
    "final['Age'] = final['bue_dob'].apply(calculate_age)\n",
    "\n",
    "# Optional: check distribution\n",
    "print(final['Age'].value_counts(dropna=False).head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1da195c5-f3c5-4777-b928-1b5d7b248a13",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Convert all object type columns to category\n",
    "object_columns = final.select_dtypes(include='object').columns\n",
    "final[object_columns] = final[object_columns].astype('category')\n",
    "\n",
    "# Identify categorical columns (both category + object, just in case)\n",
    "categorical_cols = final.select_dtypes(include=['category']).columns\n",
    "\n",
    "# Drop columns with > 50 unique categories (except 'required_loan_id')\n",
    "high_cardinality = [\n",
    "    col for col in categorical_cols \n",
    "    if col != 'required_loan_id' and final[col].nunique(dropna=True) > 50\n",
    "]\n",
    "\n",
    "final.drop(columns=high_cardinality, inplace=True)\n",
    "\n",
    "print(f\"Converted {len(object_columns)} object columns to category\")\n",
    "print(f\"Dropped {len(high_cardinality)} high-cardinality categorical columns\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "47b302b6-9ab8-4c00-8019-9254dd0e74ea",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "ratio_features = {\n",
    "    \"bue_perc_no_of_open_loans\": (\"bue_no_of_open_loans\", \"bue_no_of_loans\"),\n",
    "    \"bue_perc_no_of_open_loans_lst_6months\": (\"bue_no_of_open_loans_lst_6months\", \"bue_no_of_loans\"),\n",
    "    \"bue_perc_no_of_cc_loans\": (\"bue_no_of_cc_loans\", \"bue_no_of_loans\"),\n",
    "    \"bue_perc_no_of_cc_open_loans\": (\"bue_no_of_cc_open_loans\", \"bue_no_of_open_loans\"),\n",
    "    \"bue_perc_no_of_auto_open_loans\": (\"bue_no_of_auto_open_loans\", \"bue_no_of_open_loans\"),\n",
    "    \"bue_perc_no_of_consumer_loans\": (\"bue_no_of_consumer_loans\", \"bue_no_of_loans\"),\n",
    "    \"bue_perc_no_of_consumer_open_loans\": (\"bue_no_of_consumer_open_loans\", \"bue_no_of_open_loans\"),\n",
    "    \"bue_perc_no_of_personal_loans\": (\"bue_no_of_personal_loans\", \"bue_no_of_loans\"),\n",
    "    \"bue_perc_no_of_gold_loans\": (\"bue_no_of_gold_loans\", \"bue_no_of_loans\"),\n",
    "}\n",
    "\n",
    "# Create ratios safely (avoid division by zero)\n",
    "for new_col, (num, denom) in ratio_features.items():\n",
    "    final[new_col] = np.where(\n",
    "        final[denom] > 0,\n",
    "        np.round(final[num] / final[denom], 2),\n",
    "        np.nan  # assign NaN if denominator is 0 or missing\n",
    "    )\n",
    "\n",
    "# Inspect a sample of created features along with target\n",
    "print(final[list(ratio_features.keys()) + ['bue_min_count_of_emi', 'target_30_dpd']].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "be59f4b1-72c7-4b5c-99e7-458b311181f9",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Columns to drop\n",
    "drop_columns = [\n",
    "    'source','data_from','_merge','task_id','status','occupation',\n",
    "    'lr_created_date','bue_dob','disbursement_completion_date',\n",
    "    'month_year','Age','bue_min_count_of_emi'\n",
    "]\n",
    "\n",
    "# Inspect example column before dropping (optional)\n",
    "#print(final['s3e_email_data_linked_data_skype_creation_time'].value_counts(dropna=False).head())\n",
    "\n",
    "# Save dtypes for reference\n",
    "dtype_df = final.dtypes.reset_index()\n",
    "dtype_df.columns = ['column_name', 'dtype']\n",
    "dtype_df.to_csv(\"/Volumes/ispl_databricks/default/training/MW_Train/data_types.csv\", index=False)\n",
    "\n",
    "# Drop unwanted columns\n",
    "base_df1 = final.drop(columns=drop_columns, axis=1, errors='ignore')\n",
    "\n",
    "# Separate numeric and categorical\n",
    "df_num = base_df1.select_dtypes(include=['float64', 'int64', 'int32']).copy()\n",
    "df_cat = base_df1.select_dtypes(include=['object', 'boolean', 'category']).copy()\n",
    "\n",
    "# Fill missing numeric values with 0\n",
    "df_num = df_num.fillna(0)\n",
    "\n",
    "# Combine numeric + categorical back\n",
    "base_df2 = pd.concat([df_num, df_cat], axis=1)\n",
    "\n",
    "# Rename column safely\n",
    "base_df2 = base_df2.rename(columns={'required_loan_id': 'loan_id'})\n",
    "\n",
    "print(\"Final dataset shape:\", base_df2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e63874ef-ba95-47b6-8211-a3213a064504",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# === Column Type Analysis ===\n",
    "print(\"=== Column Type Analysis ===\")\n",
    "print(f\"Total columns in base_df2: {len(base_df2.columns)}\")\n",
    "\n",
    "# Identify categorical columns\n",
    "categorical_columns = base_df2.select_dtypes(include=['object', 'category', 'boolean']).columns.tolist()\n",
    "print(f\"Number of categorical columns: {len(categorical_columns)}\")\n",
    "if categorical_columns:\n",
    "    print(\"Sample categorical columns:\", categorical_columns[:10], \"...\" if len(categorical_columns) > 10 else \"\")\n",
    "\n",
    "# Identify numerical columns\n",
    "numerical_columns = base_df2.select_dtypes(include=['int64', 'float64', 'int32', 'float32']).columns.tolist()\n",
    "print(f\"Number of numerical columns: {len(numerical_columns)}\")\n",
    "if numerical_columns:\n",
    "    print(\"Sample numerical columns:\", numerical_columns[:10], \"...\" if len(numerical_columns) > 10 else \"\")\n",
    "\n",
    "# Identify other/unsupported dtypes\n",
    "other_columns = base_df2.select_dtypes(\n",
    "    exclude=['object', 'category', 'boolean', 'int64', 'float64', 'int32', 'float32']\n",
    ").columns.tolist()\n",
    "print(f\"Number of other type columns: {len(other_columns)}\")\n",
    "if other_columns:\n",
    "    print(\"Other type columns:\", other_columns)\n",
    "\n",
    "# Summary by dtype\n",
    "print(\"\\n=== Data Type Summary ===\")\n",
    "print(base_df2.dtypes.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "94253626-aacd-45c4-8c74-48f0ee268fee",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Calculate percentage of missing values per column\n",
    "null_percentages = base_df2.isnull().mean() * 100\n",
    "\n",
    "# Identify columns with >= 40% missing values\n",
    "columns_to_drop = null_percentages[null_percentages >= 40].index.tolist()\n",
    "\n",
    "# Drop those columns safely\n",
    "base_df2.drop(columns=columns_to_drop, inplace=True, errors='ignore')\n",
    "\n",
    "# Log info\n",
    "print(f\"Dropped {len(columns_to_drop)} columns with >=40% missing values:\")\n",
    "if columns_to_drop:\n",
    "    print(columns_to_drop[:10], \"...\" if len(columns_to_drop) > 10 else \"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "860525dd-3f27-42dc-9cf9-2d2a445390cb",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "model_name = 'ispl_databricks.model_logs.final_mw_model'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "903ae9fc-43a6-4a9e-96cf-15084ef83263",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "model_uri = f\"models:/{model_name}/4\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ff275ecb-dd5f-42e8-b0ef-c6b96472efd8",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "model_info = mlflow.models.get_model_info(model_uri)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ec05f9a2-54ac-404f-bf42-6ff674de830b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "feature_names = model_info.signature.inputs.input_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "007e9b28-d1dc-47b1-8012-20370e206cc0",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "features = feature_names + ['loan_id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6fc085fa-373b-4a66-9289-a20fbeff31ae",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "base_4 = base_df2[features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a65a2dc7-ffb3-4d53-9d71-10c0ba0520ad",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "label_encoders = {}\n",
    "\n",
    "for col in base_4.columns:\n",
    "    dtype = base_4[col].dtype\n",
    "\n",
    "    if col == \"loan_id\":\n",
    "        continue\n",
    "\n",
    "    if dtype.name in [\"category\", \"object\"]:\n",
    "        le = LabelEncoder()\n",
    "        base_4[col] = le.fit_transform(\n",
    "            base_4[col].astype(str)\n",
    "        )\n",
    "        label_encoders[col] = le"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "fed73c57-df3d-4990-9e8e-538a56904cae",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "base_4.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "af7c690c-9a92-489f-86b1-138c49484876",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "base_4 = base_4.drop_duplicates(subset=['loan_id'], keep='first')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "33e0e781-8200-4684-bf7f-e8e45532addc",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "spark_df  = spark.createDataFrame(base_4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "940a1b98-dee8-4d09-a0b0-1c15cb7b85e4",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "fe = FeatureEngineeringClient()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1b967118-2b94-443f-a53d-ee61f84abd06",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "fe.create_table(\n",
    "  name=\"ispl_databricks.model_logs.mw_sample\",\n",
    "  primary_keys=[\"loan_id\"],\n",
    "  df=spark_df,\n",
    "  description = 'sample features for mw'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c6da7b3e-6c38-49c0-b28a-bc5c36b7b9a4",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "fe.write_table(\n",
    "    name=\"ispl_databricks.model_logs.mw_sample\",\n",
    "    df=spark_df,\n",
    "    mode = \"merge\"\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "4"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "feature_store_for_sample_data",
   "widgets": {
    "training_csv": {
     "currentValue": "/Volumes/ispl_databricks/default/training/MW_Train/merged_data_corrected.csv",
     "nuid": "2f539670-e42e-43c3-979b-717dbaabafcd",
     "typedWidgetInfo": {
      "autoCreated": false,
      "defaultValue": "",
      "label": null,
      "name": "training_csv",
      "options": {
       "widgetDisplayType": "Text",
       "validationRegex": null
      },
      "parameterDataType": "String"
     },
     "widgetInfo": {
      "widgetType": "text",
      "defaultValue": "",
      "label": null,
      "name": "training_csv",
      "options": {
       "widgetType": "text",
       "autoCreated": null,
       "validationRegex": null
      }
     }
    }
   }
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
