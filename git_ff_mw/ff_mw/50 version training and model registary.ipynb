{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f3371f12-a097-4d88-ad2b-c13951795e7f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "!pip install lightgbm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "856c0a2a-7c98-4e1a-b2e5-0f975fafc4b6",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "pip install hyperopt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ad04cf08-77c5-42e3-b7f7-066ce10ca9e1",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%pip install databricks-feature_engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9ae25e3c-a34c-4cd6-aadc-854155dad7f7",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%restart_python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d7e0198f-f526-4444-bfbe-9c55fa590af1",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "import pickle\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import lightgbm as lgb\n",
    "import joblib\n",
    "from datetime import datetime, date\n",
    "import mlflow\n",
    "import mlflow.lightgbm\n",
    "from sklearn.metrics import classification_report,roc_auc_score,f1_score\n",
    "from mlflow.models.signature import infer_signature\n",
    "from hyperopt import fmin, tpe, hp, Trials, STATUS_OK\n",
    "from hyperopt.pyll.base import scope\n",
    "from databricks.feature_engineering import FeatureEngineeringClient\n",
    "from databricks.feature_engineering import FeatureEngineeringClient, FeatureLookup\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import json\n",
    "import requests\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "from pyspark.sql.functions import col\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "bb63d3e7-147b-42b2-afc3-45baf1e58feb",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "\n",
    "This pipeline performs hyperparameter optimization for a LightGBM classifier using Hyperopt. For each trial, a model is trained on the training dataset, evaluated on a validation set, and tracked as a nested MLflow run. Hyperparameters and accuracy metrics are logged for experiment comparison, while validation log loss is computed and returned as the optimization objective. This design ensures systematic experimentation, reproducibility, and seamless model selection for production deployment."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "21ed105e-d72c-46b6-8b66-ce279d479edb",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Creating training and test dataset\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ee46d04e-139a-454c-a033-f008843c7858",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Load base training data from Databricks table\n",
    "# This table contains loan_id and target label\n",
    "base_df2 = spark.table(\"ispl_databricks.model_logs.base_df_500features_updated\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "fddf8187-9c09-42f9-ac6d-8184cbed7971",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Extract only the primary key and target label\n",
    "# This will act as the label DataFrame\n",
    "spark_label =  base_df2.select(col('loan_id'),col('target_30_dpd'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "08ab2237-1cd7-47a3-8a83-40aef8d5e636",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "fe = FeatureEngineeringClient()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "30f50a1e-8176-4fca-9a3f-fff5272c86dc",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Create a Feature Store training set\n",
    "# This joins:\n",
    "#   - Labels (loan_id, target)\n",
    "#   - Features from Feature Store\n",
    "# Using loan_id as the lookup key\n",
    "training_set = fe.create_training_set(\n",
    "    df=spark_label,\n",
    "    feature_lookups=[\n",
    "        FeatureLookup(\n",
    "            table_name=\"ispl_databricks.model_logs.mw_final_feature_store\",\n",
    "            lookup_key=\"loan_id\"\n",
    "        )\n",
    "    ],\n",
    "    label=\"target_30_dpd\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "052bc912-6a55-42b0-a091-04bc8b59a9f8",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "# --------------------------------------------\n",
    "# Load the training set as a Spark DataFrame\n",
    "# Then convert it to Pandas for model training\n",
    "# --------------------------------------------\n",
    "train_pd = training_set.load_df().toPandas()\n",
    "# Remove rows with missing values\n",
    "# Ensures clean data for model training\n",
    "train_x  = train_pd.drop(['loan_id','target_30_dpd'], axis=1)\n",
    "# Separate features (X) and target (y)\n",
    "# Remove:\n",
    "#   - loan_id (primary key)\n",
    "#   - target (label)\n",
    "train_y = train_pd['target_30_dpd']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "bdb59ffa-00cc-4ebe-9719-dd398184195b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(train_x, train_y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "aa791de3-3211-4267-b71d-2bc0ea93e5d0",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "data_version = 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "1f88ce1e-7c0d-4fa7-a503-7ff124628b4e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### hyperopt experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "acc96fbe-7e9a-47b3-aba3-88c2a26ffdeb",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0cc9b762-18a5-4340-823d-8bd399d4f138",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "mlflow.set_experiment(\"/Workspace/Shared/ff_mw/ff_mw/MW_LightGBM_Top50_Training\")\n",
    "if mlflow.active_run():\n",
    "    mlflow.end_run()\n",
    "\n",
    "# Train or load LGBMClassifier\n",
    "with mlflow.start_run(run_name=f\"LGBM_{data_version}\") as run:\n",
    "\n",
    "        # -----------------------------\n",
    "        # Hyperparameter tuning section\n",
    "        # -----------------------------\n",
    "    search_space = {\n",
    "            'num_leaves': scope.int(hp.quniform('num_leaves', 20, 150, 1)),\n",
    "            'max_depth': scope.int(hp.quniform('max_depth', 3, 15, 1)),\n",
    "            'learning_rate': hp.uniform('learning_rate', 0.01, 0.3),\n",
    "            'n_estimators': scope.int(hp.quniform('n_estimators', 100, 800, 50)),\n",
    "            'min_child_samples': scope.int(hp.quniform('min_child_samples', 10, 100, 5)),\n",
    "            'subsample': hp.uniform('subsample', 0.6, 1.0),\n",
    "            'colsample_bytree': hp.uniform('colsample_bytree', 0.6, 1.0)\n",
    "        }\n",
    "\n",
    "    def objective(params):\n",
    "        with mlflow.start_run(nested=True):\n",
    "            model = lgb.LGBMClassifier(\n",
    "                random_state=42,\n",
    "                class_weight='balanced',\n",
    "                **params\n",
    "            )\n",
    "            model.fit(\n",
    "                X_train, y_train,\n",
    "                eval_set=[(X_test, y_test)],\n",
    "                eval_metric=\"binary_logloss\"\n",
    "            )\n",
    "            y_pred = model.predict(X_test)\n",
    "            acc = accuracy_score(y_test,y_pred)\n",
    "            mlflow.log_metric('accuracy', acc)\n",
    "            mlflow.log_params(params)\n",
    "            val_pred_proba = model.predict_proba(X_test)[:, 1]\n",
    "            val_logloss = -((y_test * np.log(val_pred_proba) + (1 - y_test) * np.log(1 - val_pred_proba)).mean())\n",
    "            return {'loss': val_logloss, 'status': STATUS_OK}\n",
    "\n",
    "    trials = Trials()\n",
    "    best_params = fmin(\n",
    "            fn=objective,\n",
    "            space=search_space,\n",
    "            algo=tpe.suggest,\n",
    "            max_evals=30,\n",
    "            trials=trials,\n",
    "            rstate=np.random.default_rng(42)\n",
    "        )\n",
    "\n",
    "        # Convert integer-like floats back to ints\n",
    "    best_params = {\n",
    "            k: int(v) if isinstance(v, float) and v.is_integer() else v\n",
    "            for k, v in best_params.items()\n",
    "        }\n",
    "\n",
    "    mlflow.log_params(best_params)\n",
    "    mlflow.log_param(\"class_weight\", \"balanced\")\n",
    "    mlflow.log_param(\"random_state\", 42)\n",
    "\n",
    "        # -----------------------------\n",
    "        # Train final model with best params\n",
    "        # -----------------------------\n",
    "    model = lgb.LGBMClassifier(\n",
    "            random_state=42,\n",
    "            class_weight='balanced',\n",
    "            **best_params\n",
    "        )\n",
    "\n",
    "    model = model.fit(\n",
    "            X_train,\n",
    "            y_train,\n",
    "            eval_set=[(X_train, y_train), (X_test, y_test)],\n",
    "            eval_names=[\"train\", \"valid\"],\n",
    "            eval_metric=[\"binary_logloss\"]\n",
    "        )\n",
    "    acc = accuracy_score(y_test, model.predict(X_test))\n",
    "    mlflow.log_metric(\"test_accuracy\", acc)\n",
    "    \n",
    "    \n",
    "\n",
    "        # Infer model signature from training data and predictions\n",
    "    \n",
    "\n",
    "        # Save the trained model locally\n",
    "    joblib.dump(model,'/Workspace/Shared/ff_mw/ff_mw/model_artifacts/mwtop50_new.pkl')\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "3b56f26b-3b89-4596-9490-6e26443b0a74",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "#### saving model as well as metrics in model artifacts folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d017ce6d-0285-4109-adf6-42831718f4da",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# get the features name\n",
    "trained_feature_names = model.feature_name_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "83e1bde9-e3ed-4c55-b623-6b481bc8279b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "len(trained_feature_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ca4cd1e5-a165-43a6-b958-3644f514d5f3",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# creating json file containing feature name accuracy so while creating a wrapper class to log model to avoid features mismatch and logged accuracy in mlflow run\n",
    "features_json =  {'features' : trained_feature_names,'accuracy':acc}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "233b560c-00ca-4eb3-9379-f08fbc958d5a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# saving model into model_artifacts folder\n",
    "joblib.dump(model,'/Workspace/Shared/ff_mw/ff_mw/model_artifacts/mwtop50.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4f21cf9e-a550-4e95-b970-d841474d904e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# we are saving json in model_artifact folder it will help us to log accuracy in mlflow when we will log our best model\n",
    "with open('/Workspace/Shared/ff_mw/ff_mw/model_artifacts/features.json','w') as f:\n",
    "    json.dump(features_json, f, ensure_ascii=False, indent=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "42369a6c-ec1a-4aee-af8c-7a62e96aa815",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### defining signature"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "49ef305b-a12c-4a61-b8f1-dc933aedd026",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "The signature is used for:\n",
    "\n",
    "Model Serving input validation\n",
    "\n",
    "Batch inference validation\n",
    "\n",
    "Feature mismatch protection\n",
    "\n",
    "Safe model upgrades\n",
    "\n",
    "Automated governance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "1205b19b-fc1a-460f-b685-8eae66addc8e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "we will create a input dataframe using features used in model than predict output on it define signature on input,output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a7b6d04b-85fd-4a0e-b3b7-1d433769851b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# creating model signature \n",
    "# Align input features to exactly match the features used during training\n",
    "# This avoids feature mismatch issues during inference\n",
    "input_x = train_x[trained_feature_names].iloc[[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8e8dc9f2-2c12-45b3-8c32-8e36905dced6",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# loading model\n",
    "model = joblib.load('/Workspace/Shared/ff_mw/ff_mw/model_artifacts/mwtop50_new.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d4059127-d45a-473a-bb48-99c5da03d956",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "# Generate model predictions (probability scores instead of class labels)\n",
    "# predict_proba is commonly used for classification models\n",
    "output = model.predict_proba(input_x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "619b5281-e4bc-4aa2-beeb-58fe65f13690",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "26f6206b-dbbb-4b04-b1c5-1a5869e4c207",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Infer the MLflow model signature automatically\n",
    "# The signature captures:\n",
    "#  - Input schema (feature names + data types)\n",
    "#  - Output schema (prediction shape + types)\n",
    "# This is critical for model serving and validation\n",
    "signature = infer_signature(input_x, output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "d0d041b6-1884-402e-949e-9d9fc86dad36",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### final model logging"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "69a60efe-c107-462b-bcef-d51a529ee1fd",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "creating custom wrapper class"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "a50daaa4-d865-4ad6-b8e1-4a605f20666d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "We create a custom wrapper class to hide complexity, reuse code, and keep logic consistent when working with libraries or external systems.\n",
    "It makes code cleaner, easier to change, easier to test, and lets us add common features like logging, validation, and monitoring in one place."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1919da9a-8191-40b4-9a55-55ee06bcd1be",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Custom MLflow PyFunc wrapper for model loading and inference\n",
    "# This allows the model to be served in a standardized way\n",
    "class mlwrapper(mlflow.pyfunc.PythonModel):\n",
    "\n",
    "     # Load the trained model artifact at model serving / inference time\n",
    "    def load_context(self,context):\n",
    "        # load model from model artifact folder\n",
    "        self.model = joblib.load(context.artifacts['model_artifacts']+'/mwtop50_new.pkl')\n",
    "        # Load feature metadata used during training\n",
    "        # This ensures feature consistency during inference\n",
    "        with open(context.artifacts['model_artifacts']+'/features.json', 'r') as file:\n",
    "            data = json.load(file)\n",
    "        \n",
    "        # Store the list of trained feature columns\n",
    "        self.fc = data['features']\n",
    "        print(self.fc)\n",
    "        \n",
    "    def predict(self,context,model_input):\n",
    "\n",
    "        # Align incoming inference data with trained feature columns\n",
    "        # This prevents feature mismatch issues\n",
    "        df = model_input[self.fc]\n",
    "        # Return class probability predictions\n",
    "        return self.model.predict_proba(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "755e1f1b-2317-43f5-8a93-5f9382950094",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "running mlflow experiment and registering model into unity catalog"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c9a52c36-0a65-4438-815c-1f95ba4df864",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "with mlflow.start_run():\n",
    "\n",
    "    # Log evaluation metric for the trained model\n",
    "    mlflow.log_metric(\"test_accuracy\", acc)\n",
    "\n",
    "    # Log the model using MLflow PyFunc format\n",
    "    # This makes the model deployable via MLflow Model Serving\n",
    "\n",
    "\n",
    "    mlflow.pyfunc.log_model(\n",
    "        artifact_path=\"model\",\n",
    "        python_model=mlwrapper(),\n",
    "        artifacts={\"model_artifacts\": \"/Workspace/Shared/ff_mw/ff_mw/model_artifacts\"},\n",
    "        registered_model_name=\"ispl_databricks.model_logs.final_mw_model\",\n",
    "        signature=signature\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "51bdb09a-ec3e-4ec0-957f-c6095d5a1d5a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### inference"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "c354b59e-a261-4da1-a6fe-25a526cd46b3",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "#### fetching latest model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b41d0a5c-ffd1-4084-b37a-02ac4c11fa82",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "from mlflow.tracking import MlflowClient\n",
    "client = MlflowClient()\n",
    "versions = client.search_model_versions(\"name = 'ispl_databricks.model_logs.final_mw_model'\")\n",
    "\n",
    "latest_version = sorted(versions, key=lambda v: int(v.version))[-1].version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2298967c-32a1-46dd-bc1d-3f151da84615",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "model_uri = f'models:/ispl_databricks.model_logs.final_mw_model/{latest_version}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f101b560-e98c-462e-be18-1486c07e0d4b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "model = mlflow.pyfunc.load_model(model_uri)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "99d2e8f4-8fff-4773-8b5f-db5c2cb32f0c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "####prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "29129898-a47d-418e-ac01-dcddee373fdd",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "model.predict(train_x[trained_feature_names].iloc[[3]])"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "4"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "50 version training and model registary",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
