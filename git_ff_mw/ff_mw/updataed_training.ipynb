{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3a39428a-062e-46e6-b78d-72cf3bf3b4a1",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "!pip install lightgbm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "daa31cf9-da94-4c10-a29c-f1c463810b9d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "pip install hyperopt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "947bcb16-d676-4e97-ad3d-c5b602c4a8b5",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%pip install databricks-feature_engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8161f478-81d6-4540-b982-56299b7e9ad9",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%restart_python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f9b5dd2c-76df-47da-9229-95f500c91f84",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "import pickle\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import lightgbm as lgb\n",
    "import joblib\n",
    "from datetime import datetime, date\n",
    "import mlflow\n",
    "import mlflow.lightgbm\n",
    "from sklearn.metrics import classification_report,roc_auc_score,f1_score\n",
    "from mlflow.models.signature import infer_signature\n",
    "from hyperopt import fmin, tpe, hp, Trials, STATUS_OK\n",
    "from hyperopt.pyll.base import scope\n",
    "from databricks.feature_engineering import FeatureEngineeringClient\n",
    "from databricks.feature_engineering import FeatureEngineeringClient, FeatureLookup\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import json\n",
    "import requests\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from mlflow.tracking import MlflowClient\n",
    "from sklearn.metrics import accuracy_score\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "50aa07c5-7f99-4545-b32a-327d993a0c30",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "in this notebbok we will load fetaures from feature store create training set with it"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "3cb17d33-5754-4d3d-aa91-437d9b2c67b2",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "train the model with hyperopt experiments with 30 trials "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "420442f3-fb79-4ebc-90c9-6cac3fd3d8b0",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "logged the best parameter all other trials as child run under it final save the model with best parameter registered in unity catalog"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "5cc0ed7f-3291-42c7-a6f9-caa59e240a1a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### creating training dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4499dba5-49d2-41fe-ae59-b57d3122043f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# we loading the delta table that we had saved in preprocessing notebook\n",
    "base_df2 = spark.table(\"ispl_databricks.model_logs.base_df_500features_updated\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5c85f20c-2eec-4994-abb6-1fd7b0daa279",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# we are creating spark dataframe loan_id,target to create a label dataframe for creating training data set using feautre store\n",
    "from pyspark.sql.functions import col\n",
    "spark_label =  base_df2.select(col('loan_id'), col('target_30_dpd'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "57eecdb3-71c3-4c71-b39f-79fdcb887436",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "base_df2 = base_df2.toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6f398cd3-aabc-4dfd-b4c7-0ffc504eda6c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "base_df2.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "c717a104-5820-4366-b1ed-29de8f600125",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### creating (target_30_dpd,loan_id) dataframe  for train ,test datastet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "e9e65ad8-1714-4afe-aa8a-3f17221331dd",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "we are creating this to loaf features for corresponding loan_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "dcc1a333-6853-4a0a-a49f-ccbdf20b92eb",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "target_feature = \"actual_label\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "aa555000-b5d3-4485-a6e7-33b741dcae79",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "train_data = base_df2[base_df2['type'] == 'train'].copy()\n",
    "test_data = base_df2[base_df2['type'] == 'test'].copy()\n",
    "live_data = base_df2[base_df2['type'] == 'live'].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "eb3da0db-19ef-46fd-8e53-5811682b39b3",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "train_data = train_data[['target_30_dpd','loan_id']]\n",
    "test_data = test_data[['target_30_dpd','loan_id']]\n",
    "live_data = live_data[['target_30_dpd','loan_id']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "497bb56e-9900-4375-a02b-bacb9a640a43",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "263a7e0e-cd52-49f3-9547-d4e112b92a3f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "spark_train_label = spark.createDataFrame(train_data)\n",
    "spark_test_label = spark.createDataFrame(test_data)\n",
    "spark_live_label = spark.createDataFrame(live_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "da6777c8-51d1-4424-8933-12e46e869a3d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### creating train and test dataset using features store with the help of (loan_id,target) data frame corresponding to them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "bfa2a9a0-9a01-463a-8c0a-e63fb5592f3d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "fe = FeatureEngineeringClient()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ee92cdfc-73ea-48bb-b44f-3c7a14d26d22",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#loading features for training data using spark training label dataframe and loan_id\n",
    "training_set = fe.create_training_set(\n",
    "    df=spark_train_label,\n",
    "    feature_lookups=[\n",
    "        FeatureLookup(\n",
    "            table_name=\"ispl_databricks.model_logs.mw_feature_store_500\",\n",
    "            lookup_key=\"loan_id\"\n",
    "        )\n",
    "    ],\n",
    "    label=\"target_30_dpd\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "039302cb-9150-45aa-a337-70b107cac949",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#creating x_train and y_train\n",
    "train_pd = training_set.load_df().toPandas()\n",
    "X_train = train_pd.drop(['loan_id','target_30_dpd'], axis=1)\n",
    "y_train = train_pd['target_30_dpd']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "163752b7-62d5-4963-b733-89fa78011ae1",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#loading features for test data using spark test label dataframe and loan_id\n",
    "test_set = fe.create_training_set(\n",
    "    df=spark_test_label,\n",
    "    feature_lookups=[\n",
    "        FeatureLookup(\n",
    "            table_name=\"ispl_databricks.model_logs.mw_feature_store_500\",\n",
    "            lookup_key=\"loan_id\"\n",
    "        )\n",
    "    ],\n",
    "    label=\"target_30_dpd\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "df5ba4b5-c4f0-4684-805b-7dee7f884bda",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#creating X_test,y_test\n",
    "test_pd = test_set.load_df().toPandas()\n",
    "X_test = test_pd.drop(['loan_id','target_30_dpd'], axis=1)\n",
    "y_test = test_pd['target_30_dpd']\n",
    "# Predict on a test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "77c87f12-7086-4adc-8b66-2bfac1616d39",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "fd26c4dc-e3c9-4c3b-9326-d38d48f1d640",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Config flags and paths\n",
    "model_trainYN = 1\n",
    "data_version = \"base\"\n",
    "\n",
    "input_dir  = \"/Volumes/ispl_databricks/default/training/MW_Train/input_dir\"\n",
    "output_dir = \"/Volumes/ispl_databricks/default/training/MW_Train/OUTPUT_DIR_NEW\"\n",
    "model_dir  = \"/Volumes/ispl_databricks/default/training/MW_Train/model_dir\"\n",
    "\n",
    "\n",
    "# Create main directories if missing\n",
    "for directory in [output_dir, model_dir]:\n",
    "    os.makedirs(directory, exist_ok=True)\n",
    "\n",
    "\n",
    "# Version-specific directories\n",
    "# Choose data version (change here if needed)\n",
    "# data_version = \"data_v5_new/top_20\"\n",
    "input_dir_version  = os.path.join(input_dir, data_version)\n",
    "output_dir_version = os.path.join(output_dir, data_version)\n",
    "model_dir_version  = os.path.join(model_dir, data_version)\n",
    "\n",
    "# Create version-specific directories if missing\n",
    "for directory in [output_dir_version, model_dir_version]:\n",
    "    os.makedirs(directory, exist_ok=True)\n",
    "\n",
    "\n",
    "# Define model and feature file names\n",
    "model_file_name   = \"lgb_model.pickle\"\n",
    "feature_file_name = \"model_input_feature.pickle\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "14f53b95-010f-4181-af26-ca9a8e622d48",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### hyperopt experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a1632b13-8cb5-4cf0-8b22-86f552409ecb",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Ensure model directory exists\n",
    "os.makedirs(model_dir_version, exist_ok=True)\n",
    "\n",
    "# MLflow experiment setup\n",
    "if mlflow.active_run():\n",
    "    mlflow.end_run()\n",
    "\n",
    "mlflow.set_experiment(\"/Workspace/Shared/ff_mw/ff_mw/MW_LightGBM_Training\")\n",
    "\n",
    "with mlflow.start_run(run_name=f\"LGBM_{data_version}\") as run:\n",
    "\n",
    "    if model_trainYN == 1:\n",
    "\n",
    "        # Define search space for hyperparameter tuning\n",
    "        search_space = {\n",
    "            'num_leaves': scope.int(hp.quniform('num_leaves', 20, 150, 1)),\n",
    "            'max_depth': scope.int(hp.quniform('max_depth', 3, 15, 1)),\n",
    "            'learning_rate': hp.uniform('learning_rate', 0.01, 0.3),\n",
    "            'n_estimators': scope.int(hp.quniform('n_estimators', 100, 800, 50)),\n",
    "            'min_child_samples': scope.int(hp.quniform('min_child_samples', 10, 100, 5)),\n",
    "            'subsample': hp.uniform('subsample', 0.6, 1.0),\n",
    "            'colsample_bytree': hp.uniform('colsample_bytree', 0.6, 1.0)\n",
    "        }\n",
    "\n",
    "        # Define objective function\n",
    "        def objective(params):\n",
    "            trial_id = len(trials.trials)\n",
    "            with mlflow.start_run(run_name=f\"trial_{trial_id}_LGBM\",nested=True):\n",
    "                model = lgb.LGBMClassifier(\n",
    "                random_state=42,\n",
    "                class_weight='balanced',\n",
    "                **params\n",
    "                )\n",
    "                model.fit(\n",
    "                X_train, y_train,\n",
    "                eval_set=[(X_test, y_test)],\n",
    "                eval_metric=\"binary_logloss\"\n",
    "                )\n",
    "                val_pred_proba = model.predict_proba(X_test)[:, 1]\n",
    "                val_logloss = -((y_test * np.log(val_pred_proba) + (1 - y_test) * np.log(1 - val_pred_proba)).mean())\n",
    "                mlflow.log_metric(\"validation_logloss\", val_logloss)\n",
    "                acc = accuracy_score(y_test, model.predict(X_test))\n",
    "                mlflow.log_metric(\"accuracy\", acc)\n",
    "                mlflow.log_params(params)\n",
    "                return {'loss': val_logloss, 'status': STATUS_OK}\n",
    "\n",
    "\n",
    "           \n",
    "\n",
    "        # Run Hyperopt optimization\n",
    "        trials = Trials()\n",
    "        best_params = fmin(\n",
    "            fn=objective,\n",
    "            space=search_space,\n",
    "            algo=tpe.suggest,\n",
    "            max_evals=30,\n",
    "            trials=trials,\n",
    "            rstate=np.random.default_rng(42)\n",
    "        )\n",
    "\n",
    "        # Train final model with best params\n",
    "        best_params = {\n",
    "            k: int(v) if isinstance(v, float) and v.is_integer() else v\n",
    "            for k, v in best_params.items()\n",
    "        }\n",
    "        model = lgb.LGBMClassifier(\n",
    "            random_state=42,\n",
    "            class_weight='balanced',\n",
    "            **best_params\n",
    "        )\n",
    "\n",
    "        model.fit(\n",
    "            X_train, y_train,\n",
    "            eval_set=[(X_train, y_train), (X_test, y_test)],\n",
    "            eval_names=[\"train\", \"valid\"],\n",
    "            eval_metric=[\"binary_logloss\"]\n",
    "        )\n",
    "\n",
    "        # Log parameters and metrics to MLflow\n",
    "        mlflow.log_params(best_params)\n",
    "        mlflow.log_param(\"class_weight\", \"balanced\")\n",
    "        mlflow.log_param(\"random_state\", 42)\n",
    "        mlflow.log_param(\"num_features\", X_train.shape[1])\n",
    "\n",
    "        # Evaluate on validation set\n",
    "        val_pred_proba = model.predict_proba(X_test)[:, 1]\n",
    "        val_logloss = -((y_test * np.log(val_pred_proba) + (1 - y_test) * np.log(1 - val_pred_proba)).mean())\n",
    "        mlflow.log_metric(\"validation_logloss\", val_logloss)\n",
    "\n",
    "        # Save model locally\n",
    "        pickle.dump(model, open(os.path.join(model_dir_version, model_file_name), \"wb\"))\n",
    "        joblib.dump(model, os.path.join(model_dir_version, \"job_model.pkl\"))\n",
    "\n",
    "        # Save input feature list\n",
    "        input_feature_model = X_train.columns.tolist()\n",
    "        pickle.dump(input_feature_model, open(os.path.join(model_dir_version, feature_file_name), \"wb\"))\n",
    "\n",
    "        # Log model to MLflow and register as endpoint-ready model\n",
    "      \n",
    "\n",
    "    else:\n",
    "        # Load pre-trained model\n",
    "        model = pickle.load(open(os.path.join(model_dir_version, model_file_name), \"rb\"))\n",
    "        model = joblib.load(os.path.join(model_dir_version, \"job_model.pkl\"))\n",
    "\n",
    "        # Load input feature list\n",
    "        input_feature_model = pickle.load(open(os.path.join(model_dir_version, feature_file_name), \"rb\"))\n",
    "\n",
    "    print(f\"MLflow Run ID: {run.info.run_id}\")\n",
    "    print(f\"Model trained: {model_trainYN == 1}\")\n",
    "    print(f\"Number of input features: {len(input_feature_model)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "4ad40565-f558-4114-abe1-1d95165f1570",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### saving model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "9e3560a9-0f7f-45cb-a1b2-f59ca1329a5b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# dumping model at specific path to make it reusable\n",
    "model = pickle.load(open(os.path.join(model_dir_version, model_file_name), \"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "a3f53d0e-5b4d-483b-87aa-bf22f1193c69",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# loading the model that  save \n",
    "model = pickle.load(open(os.path.join(model_dir_version, model_file_name), \"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "fc53c0c1-eec5-4502-85bc-5aa8a86be7de",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#dumping model into model artifacts folder so that it can be easily in unity catalog\n",
    "joblib.dump(model,'/Workspace/Shared/ff_mw/ff_mw/model_artifacts/500featuresmodel.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a84b5c16-54fe-49b7-b79b-ddadfc572f73",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#loading model\n",
    "model = joblib.load('/Workspace/Shared/ff_mw/ff_mw/model_artifacts/500featuresmodel.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "8a185ef0-b949-4a4f-8cad-22e6e9fc05e7",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## ### model registary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "fc74eddc-c3d5-4282-92cd-4d049f64a695",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "###defining signature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c6dcc2db-96dc-4585-9bfa-68dba24adeda",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#getting features used in model while training or the features on which model trained this prevents the schema mismatch while loggong into mlflow or while inferencing\n",
    "training_feature = model.feature_name_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a577b861-d5fe-41a4-a9ae-ae1ca596480a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# defing an input_x as a dataframe for example or defining signature\n",
    "input_x = X_train[training_feature].iloc[[1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7f0f582c-48fa-45fc-9bca-ce4a740dd781",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# input_y for signature of output\n",
    "input_y = model.predict(input_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "aecafb38-e89e-46c7-b716-a2c94d5c5f34",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# defining  signature  as it required while logging in mlflow as it prevent schema mismatch\n",
    "signature = infer_signature(input_x, input_y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "129ae89d-2463-4897-879a-d10823b3df27",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "accuracy = accuracy_score(y_test, model.predict(X_test[training_feature]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "99c6f515-6ec8-4de4-a354-b4492ef8fb67",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "c83a99e8-9c0e-47bd-b252-4fc5c0f4f536",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "creating custom wrapper class to simplyfy registary and inferencing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9b811bde-e922-4796-a6ad-6f583e225fd7",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#This custom MLflow PyFunc wrapper loads the trained model and its feature list, ensures schema consistency at inference time, and returns probability predictions for downstream evaluation or deployment it make easy to log the model into ml flow prevents schema mismatch.\n",
    "class mlwrapper(mlflow.pyfunc.PythonModel):\n",
    "    def load_context(self,context):\n",
    "        #loading model that we had saved in artifacts\n",
    "        self.model = joblib.load(context.artifacts['model_artifacts']+'/500featuresmodel.pkl')\n",
    "         #loading features used in model\n",
    "        self.fc = model.feature_name_\n",
    "        print(self.fc)\n",
    "        \n",
    "    def predict(self,context,model_input):\n",
    "        df = model_input[self.fc]\n",
    "        return self.model.predict_proba(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "49d8eea1-068e-4078-906d-8f3c14776c89",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "registering model into unity catalog wit mlflow experiment also logging accuracy of model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9ef09e12-6ea7-4118-ae3f-9fa8ed9b3346",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Log the trained model to Unity Catalog using MLflow Model Registry\n",
    "# Catalog  : ispl_databricks\n",
    "# Schema   : model_logs\n",
    "# Model    : ffbd_lgbm_all_columns_endpoint\n",
    "# This enables centralized model governance, versioning, and deployment\n",
    "with mlflow.start_run():\n",
    "\n",
    "    # Log evaluation metric for model performance tracking\n",
    "    mlflow.log_metric(\"test_accuracy\", accuracy)\n",
    "\n",
    "    # Log the trained model using a custom MLflow PyFunc wrapper\n",
    "    # The wrapper ensures consistent feature selection and inference logic\n",
    "\n",
    "    \n",
    "\n",
    "    mlflow.pyfunc.log_model(\n",
    "        artifact_path=\"model\",\n",
    "        python_model=mlwrapper(),\n",
    "            # Path to model artifacts (e.g., serialized model files)\n",
    "        artifacts={\"model_artifacts\": '/Workspace/Shared/ff_mw/ff_mw/model_artifacts'},\n",
    "           # Register the model in Unity Catalog for lifecycle management\n",
    "        registered_model_name=\"ispl_databricks.model_logs.ffmw_lgbm_all_columns_endpoint\",\n",
    "              # Attach model signature to enforce input/output schema validation\n",
    "        signature=signature\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "0084874d-7107-4c05-bf4d-bbe25fcd9554",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### inferencing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "fd3171ce-9567-4fd9-bb2f-4b7e8e418ada",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#model_name\n",
    "model_name = 'ispl_databricks.model_logs.ffmw_lgbm_all_columns_endpoint'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1104bf44-54a0-4971-be05-37b7d84a4b09",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#loading versions of model\n",
    "client = MlflowClient()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "a25349e5-f300-40df-9dc1-b04937107ba1",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "#### fetching latest version of model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "db07d580-bd6d-4972-953a-59e30fa74253",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# fetching latest version of model\n",
    "latest_versions = client.search_model_versions(\n",
    "    f\"name='{model_name}'\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a4151a1a-2c8b-4ca3-bdaf-0af6dcd870ae",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# fetching all version and creating a list of it\n",
    "versions = [int(versions.version) for versions in latest_versions]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6e6a9adb-b80d-4e6c-89e9-dc8d49efb243",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#sorting it to get latest model in descending order\n",
    "versions.sort(reverse = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f39e4a3f-07f5-4fcf-8983-3d07707d93ed",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#fetching latest version\n",
    "latest_version = str(versions[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "710d0a55-2432-4bc6-b7c0-7464941ee052",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#defining model_uri for latest model\n",
    "model_uri = f\"models:/{model_name}/{latest_version}\"\n",
    "#loading latest model\n",
    "loaded_model = mlflow.pyfunc.load_model(model_uri)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "baa1ef3e-db81-4339-8bfd-bce35aabd9c8",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#preediction\n",
    "loaded_model.predict(X_train[training_feature].iloc[[2]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1943d593-d25b-45a8-be1c-4a265f00b203",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.figure(figsize=(10, 8))\n",
    "ax = lgb.plot_importance(model, max_num_features=20, importance_type='gain')\n",
    "plt.title(\"Top 20 Feature Importances\")\n",
    "plt.show()\n",
    "\n",
    "# Optionally, log feature importance plot to MLflow\n",
    "mlflow.log_figure(ax.figure, \"feature_importance.png\")\n",
    "\n",
    "\n",
    "# Plot training evaluation metrics (logloss over iterations)\n",
    "plt.figure(figsize=(10, 6))\n",
    "ax = lgb.plot_metric(model)\n",
    "plt.title(\"Training Evaluation Metric (Binary Logloss)\")\n",
    "plt.show()\n",
    "\n",
    "# Optionally, log evaluation metric plot to MLflow\n",
    "mlflow.log_figure(ax.figure, \"training_evaluation.png\")"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "4"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "mostRecentlyExecutedCommandWithImplicitDF": {
     "commandId": -1,
     "dataframes": [
      "_sqldf"
     ]
    },
    "pythonIndentUnit": 4
   },
   "notebookName": "updataed_training",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
