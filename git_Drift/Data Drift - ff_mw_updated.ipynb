{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2dd95862-1a32-4a1d-85c3-97254dcbbcc5",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from scipy.stats import chi2_contingency\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import date\n",
    "from pyspark.sql import functions as F\n",
    "import os\n",
    "import json\n",
    "from datetime import datetime,date\n",
    "from pyspark.sql.types import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "488d0382-8d80-4480-bab8-96e57f8a4753",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "curr_df = (\n",
    "    spark.read.table(\"ispl_databricks.ff.model_logs_payload\")\n",
    "    .filter(\"request_time >= current_date() - INTERVAL 20 DAYS\")\n",
    "    .filter(F.col(\"execution_duration_ms\").isNotNull()).toPandas()\n",
    "    \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3475f36a-18b1-40e6-9e4d-1fa44842edf6",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "result_list = []\n",
    "for _, row in curr_df.iterrows():\n",
    "    data = row['request']\n",
    "    # If you want to access 'dataframe_records', you need to load the JSON string first\n",
    "    data_dict = json.loads(data)\n",
    "    result_list.append(data_dict['dataframe_records'][0])\n",
    "curr_df = pd.DataFrame(result_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "48924dd6-4f72-4d83-8300-4046f8d2df62",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "len(curr_df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "58c6cd35-0892-4965-8ada-940e7e70dec5",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "features_df = spark.table(\"ispl_databricks.model_logs.mw_final_inference_data\").toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a725645d-375c-4811-8a8b-4bb043b9dd67",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "curr_df_schema = curr_df.dtypes.to_dict()\n",
    "ref_df_schema  = features_df.dtypes.to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "901914ab-8bb4-4d23-9937-e11d2ae60169",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def schema_check(schema1,schema2):\n",
    "    check = []\n",
    "    for j in schema1:\n",
    "        if schema1[j] == schema2[j]:\n",
    "            check.append(True)\n",
    "        else:\n",
    "            check.append(False)\n",
    "    return check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f0a1db10-884f-4b6f-b2c0-b5485c155e40",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "check = schema_check(curr_df_schema,ref_df_schema)\n",
    "check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a96e713d-9bdd-4f2b-b5bb-7f6027edd37d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "if False in check:\n",
    "    schema_drift = 'True'\n",
    "else:\n",
    "    schema_drift = 'False'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c7b26f76-3373-42f8-8d99-cc7982698320",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def dq_check(features_df,curr_df):\n",
    "  for _,rows in curr_df.iterrows():\n",
    "    if rows['bue_total_bounces_count_loan_percent'] > 100:\n",
    "      return True\n",
    "    if rows['mw_pre_active_day_percentage'] > 100:\n",
    "      return True\n",
    "    if rows['bue_perc_no_of_open_loans'] > 100:\n",
    "      return True\n",
    "    if rows['mw_pre_top_app_pct'] > 100:\n",
    "      return True\n",
    "  return False\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c68c5437-da19-4454-b46c-2d2e07b8f700",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "dq_drift = dq_check(features_df,curr_df)\n",
    "if dq_drift == True:\n",
    "    dq_drift = 'True'\n",
    "else:\n",
    "    dq_drift = 'False'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f7428aa3-175a-4bdf-a975-625da87bde61",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def null_value_checks(curr_df, ref_df):\n",
    "    for x in ref_df.columns:\n",
    "        if x not in curr_df.columns:\n",
    "            continue  # Skip columns not present in curr_df\n",
    "        miss_count_ref_percentage = (\n",
    "            (ref_df[x] == -1).sum() / len(ref_df) * 100\n",
    "        )\n",
    "        miss_count_curr_percentage = (\n",
    "            (curr_df[x] == -1).sum() / len(curr_df) * 100\n",
    "        )\n",
    "        if (\n",
    "            miss_count_curr_percentage > miss_count_ref_percentage + 10\n",
    "            or miss_count_curr_percentage < miss_count_ref_percentage - 10\n",
    "        ):\n",
    "            return False\n",
    "    return True\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "130b9d3d-0037-4a32-affa-9fbdee010e2c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "null_value_checks  = null_value_checks(curr_df,features_df)\n",
    "if null_value_checks == False:\n",
    "    null_value_drift = 'True'\n",
    "else:\n",
    "    null_value_drift = 'False'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c9193008-f040-41b4-b09a-1a84976b3df2",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "\n",
    "delete  from ispl_databricks.ff.model_logs_payload\n",
    "where   execution_duration_ms is  null"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9275d15b-c2f7-44a8-8f5b-0c32fac1f1ca",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "select * from ispl_databricks.ff.model_logs_payload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d9840c3f-347f-4805-8338-2de30515a4a4",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Databricks widgets (Job Parameters)\n",
    "dbutils.widgets.text(\"model_name\", \"ff_mw\", \"Model Name\")\n",
    "dbutils.widgets.text(\"mean_diff_threshold\", \"0.2\", \"Mean Diff Threshold (Fraction)\")\n",
    "dbutils.widgets.text(\"std_diff_threshold\", \"0.3\", \"Std Diff Threshold (Fraction)\")\n",
    "dbutils.widgets.text(\"pvalue_threshold\", \"0.05\", \"Chi-Square p-value Threshold\")\n",
    "\n",
    "# Read job parameter values\n",
    "model_name = dbutils.widgets.get(\"model_name\")\n",
    "mean_diff_threshold = float(dbutils.widgets.get(\"mean_diff_threshold\"))\n",
    "std_diff_threshold = float(dbutils.widgets.get(\"std_diff_threshold\"))\n",
    "pvalue_threshold = float(dbutils.widgets.get(\"pvalue_threshold\"))\n",
    "\n",
    "print(f\"üèÉ Running data drift detection for model: {model_name}\")\n",
    "print(f\"üîπ Mean threshold: {mean_diff_threshold}, Std threshold: {std_diff_threshold}, p-value: {pvalue_threshold}\")\n",
    "\n",
    "# Import dependencies\n",
    "from scipy.stats import chi2_contingency\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import date\n",
    "from pyspark.sql import functions as F\n",
    "import os\n",
    "import json\n",
    "# --- Load reference and current (inference) datasets ---\n",
    "\n",
    "curr_df = (\n",
    "    spark.read.table(\"ispl_databricks.ff.model_logs_payload\")\n",
    "    .filter(\"request_time >= current_date() - INTERVAL 30 DAYS\")\n",
    "    .filter(F.col(\"execution_duration_ms\").isNotNull())\n",
    "    .toPandas()\n",
    ")\n",
    "result_list = []\n",
    "\n",
    "for _, row in curr_df.iterrows():\n",
    "    data = row['request']\n",
    "    # If you want to access 'dataframe_records', you need to load the JSON string first\n",
    "    data_dict = json.loads(data)\n",
    "    result_list.append(data_dict['dataframe_records'][0])\n",
    "curr_df = pd.DataFrame(result_list)\n",
    "print(curr_df.columns)\n",
    "\n",
    "features_df = spark.table(\"ispl_databricks.model_logs.mw_final_inference_data\").toPandas().head(20)\n",
    "ref_df = features_df.drop([\"loan_id\"], axis=1)\n",
    "#curr_df = curr_df.drop(columns = [\"loan_id\"])\n",
    "features = curr_df.columns.tolist()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# --- Define features to monitor ---\n",
    "cat_cols = ref_df.select_dtypes(include=[\"object\", \"category\"]).columns.tolist()\n",
    "num_cols = ref_df.select_dtypes(include=[\"int\", \"float\", \"number\"]).columns.tolist()\n",
    "\n",
    "results = []\n",
    "evaluation_date = date.today()\n",
    "\n",
    "# --- 1. Categorical Columns: Chi-Square Test ---\n",
    "for col in cat_cols:\n",
    "    try:\n",
    "        ref_counts = ref_df[col].value_counts()\n",
    "        cur_counts = curr_df[col].value_counts()\n",
    "\n",
    "        all_categories = set(ref_counts.index).union(set(cur_counts.index))\n",
    "        ref_aligned = [ref_counts.get(c, 0) for c in all_categories]\n",
    "        cur_aligned = [cur_counts.get(c, 0) for c in all_categories]\n",
    "\n",
    "        chi2, p, _, _ = chi2_contingency([ref_aligned, cur_aligned])\n",
    "        drift_status_cat = \"Drift\" if p < pvalue_threshold else \"Stable\"\n",
    "\n",
    "        results.append((\n",
    "            evaluation_date,\n",
    "            \"ff_mw\",\n",
    "            col,\n",
    "            \"categorical\",\n",
    "            \"chi_square\",\n",
    "            float(p),\n",
    "            drift_status_cat,\n",
    "            int(len(ref_df)),\n",
    "            int(len(curr_df)),\n",
    "            None\n",
    "        ))\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"‚ö†Ô∏è Skipped {col} due to error: {e}\")\n",
    "\n",
    "# --- 2. Numeric Columns: Mean & Std Deviation Comparison ---\n",
    "for col in num_cols:\n",
    "    try:\n",
    "        mean_ref, mean_cur = ref_df[col].mean(), curr_df[col].mean()\n",
    "        std_ref, std_cur = ref_df[col].std(), curr_df[col].std()\n",
    "\n",
    "        mean_diff = abs(mean_cur - mean_ref) / (abs(mean_ref) + 1e-6)\n",
    "        std_diff = abs(std_cur - std_ref) / (abs(std_ref) + 1e-6)\n",
    "\n",
    "        drift_status_num = \"Drift\" if (mean_diff > mean_diff_threshold or std_diff > std_diff_threshold) else \"Stable\"\n",
    "\n",
    "        results.append((\n",
    "            evaluation_date,\n",
    "            \"ff_mw\",\n",
    "            col,\n",
    "            \"numeric\",\n",
    "            \"mean_std\",\n",
    "            float(max(mean_diff, std_diff)),\n",
    "            drift_status_num,\n",
    "            int(len(ref_df)),\n",
    "            int(len(curr_df)),\n",
    "            None,\n",
    "            None\n",
    "        ))\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"‚ö†Ô∏è Skipped {col} due to error: {e}\")\n",
    "\n",
    "# -------------------------------------------------------------\n",
    "# ‚≠ê NEW: GLOBAL DRIFT STATUS (Do not modify per-column results)\n",
    "# -------------------------------------------------------------\n",
    "drift_count = sum(1 for r in results if r[6] == \"Drift\")  # index 6 = drift_status\n",
    "drift_status = \"Drift\" if drift_count >= 20 else \"Stable\"\n",
    "\n",
    "print(f\"üîî Per-feature drift count = {drift_count}\")\n",
    "print(f\"üåê Global drift status = {drift_status}\")\n",
    "# -------------------------------------------------------------\n",
    "\n",
    "# --- Create DataFrame & Write to Delta Table ---\n",
    "from pyspark.sql.types import (\n",
    "    StructType,\n",
    "    StructField,\n",
    "    StringType,\n",
    "    IntegerType,\n",
    "    FloatType,\n",
    "    DateType,\n",
    "    DoubleType,\n",
    "    TimestampType\n",
    "\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "schema = StructType([\n",
    "    StructField(\"evaluation_date\", DateType(), True),\n",
    "    StructField(\"model_name\", StringType(), True),\n",
    "    StructField(\"feature_name\", StringType(), True),\n",
    "    StructField(\"feature_type\", StringType(), True),\n",
    "    StructField(\"metric_used\", StringType(), True),\n",
    "    StructField(\"metric_value\", DoubleType(), True),\n",
    "    StructField(\"drift_status\", StringType(), True),\n",
    "    StructField(\"ref_sample_size\", IntegerType(), True),\n",
    "    StructField(\"cur_sample_size\", IntegerType(), True),\n",
    "    StructField(\"comment\", StringType(), True),\n",
    "    StructField(\"created_at\", TimestampType(), True),\n",
    "])\n",
    "\n",
    "if results:\n",
    "    drift_df = spark.createDataFrame(results, schema)\n",
    "    drift_df = drift_df.withColumn(\"created_at\", F.current_timestamp())\n",
    "    drift_df = drift_df.drop(\"global_drift_status\")\n",
    "    drift_df = drift_df.withColumn(\"metric_value\", drift_df[\"metric_value\"].cast(\"double\"))\n",
    "    drift_df.write.format(\"delta\").mode(\"append\").saveAsTable(\"ispl_databricks.model_logs.data_drift_log\")\n",
    "    display(drift_df.printSchema())\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è No results to log ‚Äî check your reference and inference tables.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f9b58eb3-fcaf-4af0-8d56-968c30c3a1a8",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "select * from ispl_databricks.model_logs.data_drift_log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0301f995-3b57-4b45-a82f-e6baf1f22b06",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "select * from ispl_databricks.ff.model_logs_payload\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1f5b3cd8-3223-4767-8332-2ddf9ad96d7b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "dbutils.jobs.taskValues.set(\"schema_drift\", schema_drift)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d6b009dc-f06c-4650-8fae-1a7461f9c305",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "dbutils.jobs.taskValues.set(\"drift_flag\", drift_status)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "520289e0-d5b6-43e3-ae8d-4199b04d1ad8",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "dbutils.jobs.taskValues.set(\"dq_drift\", dq_drift)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "f65a5586-1b71-43fd-a921-cd91a2ea938e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "dbutils.jobs.taskValues.set(\"null_value_drift\", null_value_drift )"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": {
    "hardware": {
     "accelerator": null,
     "gpuPoolId": null,
     "memory": null
    }
   },
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "4"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "mostRecentlyExecutedCommandWithImplicitDF": {
     "commandId": 2441562357367041,
     "dataframes": [
      "_sqldf"
     ]
    },
    "pythonIndentUnit": 4
   },
   "notebookName": "Data Drift - ff_mw_updated",
   "widgets": {
    "mean_diff_threshold": {
     "currentValue": "0.2",
     "nuid": "aec44fd2-2910-401d-9291-e3eb3429e1a7",
     "typedWidgetInfo": {
      "autoCreated": false,
      "defaultValue": "0.2",
      "label": "Mean Diff Threshold (Fraction)",
      "name": "mean_diff_threshold",
      "options": {
       "widgetDisplayType": "Text",
       "validationRegex": null
      },
      "parameterDataType": "String"
     },
     "widgetInfo": {
      "widgetType": "text",
      "defaultValue": "0.2",
      "label": "Mean Diff Threshold (Fraction)",
      "name": "mean_diff_threshold",
      "options": {
       "widgetType": "text",
       "autoCreated": null,
       "validationRegex": null
      }
     }
    },
    "model_name": {
     "currentValue": "loan_approval_model",
     "nuid": "074a0a8e-223b-4a5a-adb2-4511810e007a",
     "typedWidgetInfo": {
      "autoCreated": false,
      "defaultValue": "ff_mw",
      "label": "Model Name",
      "name": "model_name",
      "options": {
       "widgetDisplayType": "Text",
       "validationRegex": null
      },
      "parameterDataType": "String"
     },
     "widgetInfo": {
      "widgetType": "text",
      "defaultValue": "ff_mw",
      "label": "Model Name",
      "name": "model_name",
      "options": {
       "widgetType": "text",
       "autoCreated": null,
       "validationRegex": null
      }
     }
    },
    "pvalue_threshold": {
     "currentValue": "0.05",
     "nuid": "e182f038-e2c9-42ca-b98a-4380135b19f0",
     "typedWidgetInfo": {
      "autoCreated": false,
      "defaultValue": "0.05",
      "label": "Chi-Square p-value Threshold",
      "name": "pvalue_threshold",
      "options": {
       "widgetDisplayType": "Text",
       "validationRegex": null
      },
      "parameterDataType": "String"
     },
     "widgetInfo": {
      "widgetType": "text",
      "defaultValue": "0.05",
      "label": "Chi-Square p-value Threshold",
      "name": "pvalue_threshold",
      "options": {
       "widgetType": "text",
       "autoCreated": null,
       "validationRegex": null
      }
     }
    },
    "std_diff_threshold": {
     "currentValue": "0.3",
     "nuid": "9e82497c-653c-4d24-9409-ad30eebf3706",
     "typedWidgetInfo": {
      "autoCreated": false,
      "defaultValue": "0.3",
      "label": "Std Diff Threshold (Fraction)",
      "name": "std_diff_threshold",
      "options": {
       "widgetDisplayType": "Text",
       "validationRegex": null
      },
      "parameterDataType": "String"
     },
     "widgetInfo": {
      "widgetType": "text",
      "defaultValue": "0.3",
      "label": "Std Diff Threshold (Fraction)",
      "name": "std_diff_threshold",
      "options": {
       "widgetType": "text",
       "autoCreated": null,
       "validationRegex": null
      }
     }
    }
   }
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
