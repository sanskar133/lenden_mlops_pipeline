{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9af781f7-eec2-409b-a9ad-e09d5d2de30b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from scipy.stats import chi2_contingency\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import date\n",
    "from pyspark.sql import functions as F\n",
    "import os\n",
    "import json\n",
    "from datetime import datetime,date\n",
    "from pyspark.sql.types import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "ae579390-6bb1-4c76-b6ee-603f263d0866",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### data drift"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "ecb79c1f-8bf7-45c4-9b02-a56be0301627",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "take data of past 20 days inference data and check drift with current training data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "d1228e4d-7786-4cbd-a5e7-1abe38dbef9c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "schema drift : we will compare schema of both data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "8a8ac926-8f8e-4738-83b9-31bb4af85807",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "dq_checks : basic checks whether 0<age<100 or percentage is 0-100 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1df65c2b-794b-444f-b831-7a1b8e6a2546",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "null value drift: percentage of null values in the past 30 inference data should not differ by 10% from the percentage of null values in the training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "42dfe380-40e1-4a74-aeee-764116b4cfd6",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Read the table from Databricks metastore\n",
    "# Filter records from the last 20 days based on request_time\n",
    "# Keep only rows where execution_duration_ms is available (not NULL) where rrequested were succeceded\n",
    "# Convert Spark DataFrame to Pandas DataFrame for local analysis\n",
    "curr_df = (\n",
    "    spark.read.table(\"ispl_databricks.model_logs.ff_bd_payload\")\n",
    "    .filter(\"request_time >= current_date() - INTERVAL 20 DAYS\")\n",
    "    .filter(F.col(\"execution_duration_ms\").isNotNull()).toPandas()\n",
    "    \n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "b6836cd2-5c73-47b3-b469-20dec658523b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### extracting features used by model from request column in inference table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b8d4b130-9383-437d-bade-4b4cfbac1f26",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Initialize an empty list to store extracted records\n",
    "result_list = []\n",
    "# Iterate over each row in the Pandas DataFrame\n",
    "for _, row in curr_df.iterrows():\n",
    "\n",
    "    # Extract the JSON string stored in the 'request' column\n",
    "    data = row['request']\n",
    "    # If you want to access 'dataframe_records', you need to load the JSON string first\n",
    "    data_dict = json.loads(data)\n",
    "\n",
    "    # Extract the first record from 'dataframe_records'\n",
    "    # (Assumes dataframe_records is a list and at least one element exists)\n",
    "    result_list.append(data_dict['dataframe_records'][0])\n",
    "curr_df = pd.DataFrame(result_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "fe163924-04d9-4664-8a6d-46fbbcf3f0c9",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "curr_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "229564b4-e991-4ace-8c3b-2555b7ba551d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "loading the training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "acb6d991-0fad-4059-9567-939c246e1553",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "features_df = spark.table(\"ispl_databricks.model_logs.bd_final_feature_stores\").toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "16fc3051-1068-4f0f-9aec-4e9f98cae4b1",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Schema_check"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "f4560fa2-b1c5-4752-99e5-54c33cccef98",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "comparing each column with their data types of both data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5f68e913-f3a2-4325-ad52-673598882c66",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "curr_df_schema = curr_df.dtypes.to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d76fdc9c-ad58-490c-a92a-c9d5258adf61",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "ref_df_schema  = features_df.dtypes.to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "be973539-43a7-4ca9-a83c-503df240829b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "curr_df_schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ac756fec-472c-4ff8-95ee-1e08af3116f9",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def schema_check(schema1,schema2):\n",
    "     # Initialize a list to store comparison results for each field\n",
    "    check = []\n",
    "\n",
    "    # Iterate over each key (column/field) in the first schema\n",
    "    for j in schema1:\n",
    "\n",
    "        # Compare the data type/value of the current field in both schemas\n",
    "        if schema1[j] == schema2[j]:\n",
    "         # Append True if schemas match for this field\n",
    "            check.append(True)\n",
    "        else:\n",
    "                 # Append False if schemas do not match for this field\n",
    "            check.append(False)\n",
    "    \n",
    "    # Return list indicating match/mismatch for each field\n",
    "    return check\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ed9145f2-7250-4af8-8874-feaab23f704d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "check = schema_check(curr_df_schema,ref_df_schema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3ca51c8e-3280-4718-a080-f76e8473e203",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ecb7701c-45fb-488f-9719-bcc6ab03372a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Check if any schema mismatch exists\n",
    "if False in check:\n",
    "     # If at least one field does not match, schema drift is detected\n",
    "    schema_drift = 'True'\n",
    "     # If all fields match, no schema drift is detected\n",
    "else:\n",
    "    schema_drift = 'False'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "5085d454-b18e-4713-9870-54e59331b575",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### dq_checks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "4201a49a-0231-4e6e-8ad3-304b46382424",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "add basic conditions check to get dq_check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6997d83d-3db7-4106-80bd-86a4d3ea1dea",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def dq_checks(df):\n",
    "       # Iterate over each row in the DataFrame\n",
    "    for _,rows in df.iterrows():\n",
    "         # Check if phone digital age exceeds allowed threshold\n",
    "        if rows['phone_phoneNameDigitalAge'] > 20000:\n",
    "            return True\n",
    "        \n",
    "        # Check if email digital age exceeds allowed threshold\n",
    "        if rows['email_emailNameDigitalAge'] > 20000:\n",
    "            return True\n",
    "        \n",
    "        # Check if bureau age is unrealistically high\n",
    "        if rows['bue_age'] > 100:\n",
    "            return True\n",
    "         \n",
    "        # Check if email-name match score exceeds valid range\n",
    "        if rows['email_nameEmailMatch'] > 100:\n",
    "            return True\n",
    "              # Check if UPI name similarity score exceeds valid range\n",
    "        if rows['upi_name_similarity'] > 100:\n",
    "            return True\n",
    "    return False\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "540c8201-e27d-42a4-ac82-99fd0ccac6ac",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "if dq_checks function return True then there is dq_droft else no"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e7254f14-d787-4c55-9ca6-c4863d020d1b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "dq_drift = dq_checks(curr_df)\n",
    "if dq_drift == True:\n",
    "    dq_drift = 'True'\n",
    "else:\n",
    "    dq_drift = 'False'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "50adb89b-7b0b-4687-93d8-6054f393ad28",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### null_value_drift"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "557003a3-f0c5-4f99-8d65-538376243507",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%python\n",
    "def null_value_checks(curr_df, ref_df):\n",
    "        # Iterate over each column in the reference DataFrame\n",
    "    for x in ref_df.columns:\n",
    "\n",
    "        # Calculate percentage of missing values in the reference data\n",
    "        # (Assumes -1 represents missing values)\n",
    "        miss_count_ref_percentage = (\n",
    "            (ref_df[x] == -1).sum() / len(ref_df) * 100\n",
    "        )\n",
    "\n",
    "        # Calculate percentage of missing values in the current data\n",
    "        miss_count_curr_percentage = (\n",
    "            (curr_df[x] == -1).sum() / len(curr_df) * 100\n",
    "        )\n",
    "\n",
    "        # Check if the difference in missing value percentage\n",
    "        # exceeds the allowed threshold of ¬±10%\n",
    "        if (\n",
    "            miss_count_curr_percentage > miss_count_ref_percentage + 10\n",
    "            or miss_count_curr_percentage < miss_count_ref_percentage - 10\n",
    "        ):\n",
    "            \n",
    "            # Null value drift detected\n",
    "            return True\n",
    "    return False\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1aeaa049-6a75-41a5-a053-0d2476247dc5",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "null_value_checks  = null_value_checks(curr_df,features_df)\n",
    "if null_value_checks == False:\n",
    "    null_value_drift = 'False'\n",
    "else:\n",
    "    null_value_drift = 'True'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9b254d94-8c8b-44ef-8b09-255fcc9a20bb",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "delete  from ispl_databricks.model_logs.ff_bd_payload\n",
    "where   execution_duration_ms is  null"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8177c84d-df2c-4ea0-b7c6-2949e82506a5",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "select * from ispl_databricks.model_logs.ff_bd_payload"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "d7307235-87b9-47f0-9bf2-a01969d3f39d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### DATA DRIFT\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "d63a6718-b9ab-4989-9e30-295e26381ccc",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "compare distribution of columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "53e56c59-e68d-4d60-b385-94ed15774745",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "categorical - chi square -test\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "42258608-73ba-43f2-b5e1-1bf7915cba92",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "continious - mean diff and std diff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "29797404-34c0-4998-a1ea-eaabc995922d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "  # Databricks widgets (Job Parameters)\n",
    "dbutils.widgets.text(\"model_name\", \"ff_bd\", \"Model Name\")\n",
    "dbutils.widgets.text(\"mean_diff_threshold\", \"0.2\", \"Mean Diff Threshold (Fraction)\")\n",
    "dbutils.widgets.text(\"std_diff_threshold\", \"0.3\", \"Std Diff Threshold (Fraction)\")\n",
    "dbutils.widgets.text(\"pvalue_threshold\", \"0.05\", \"Chi-Square p-value Threshold\")\n",
    "\n",
    "# Read job parameter values\n",
    "model_name = dbutils.widgets.get(\"model_name\")\n",
    "mean_diff_threshold = float(dbutils.widgets.get(\"mean_diff_threshold\"))\n",
    "std_diff_threshold = float(dbutils.widgets.get(\"std_diff_threshold\"))\n",
    "pvalue_threshold = float(dbutils.widgets.get(\"pvalue_threshold\"))\n",
    "\n",
    "print(f\"üèÉ Running data drift detection for model: {model_name}\")\n",
    "print(f\"üîπ Mean threshold: {mean_diff_threshold}, Std threshold: {std_diff_threshold}, p-value: {pvalue_threshold}\")\n",
    "\n",
    "# Import dependencies\n",
    "from scipy.stats import chi2_contingency\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import date\n",
    "from pyspark.sql import functions as F\n",
    "import os\n",
    "import json\n",
    "from datetime import datetime,date\n",
    "# --- Load reference and current (inference) datasets ---\n",
    "\n",
    "curr_df = (\n",
    "    spark.read.table(\"ispl_databricks.model_logs.ff_bd_payload\")\n",
    "    .filter(\"request_time >= current_date() - INTERVAL 7 DAYS\")\n",
    "    .filter(F.col(\"execution_duration_ms\").isNotNull())\n",
    "    .toPandas()\n",
    ")\n",
    "result_list = []\n",
    "\n",
    "\n",
    "for _, row in curr_df.iterrows():\n",
    "    data = row['request']\n",
    "    # If you want to access 'dataframe_records', you need to load the JSON string first\n",
    "    data_dict = json.loads(data)\n",
    "    result_list.append(data_dict['dataframe_records'][0])\n",
    "curr_df = pd.DataFrame(result_list)\n",
    "print(curr_df.columns)\n",
    "features_df = spark.table(\"ispl_databricks.model_logs.bd_final_feature_stores\").toPandas()\n",
    "\n",
    "ref_df = features_df.drop([\"loan_id\"], axis=1)\n",
    "# curr_df = curr_df.drop([\"loan_id\"],axis = 1)\n",
    "features = curr_df.columns.tolist()\n",
    "# feature_imp_df = pd.DataFrame({'feature_name':model.feature_name_,'importance':model.feature_importances_})\n",
    "\n",
    "# feature_imp_df.sort_values(by=[\"importance\"],ascending=False,inplace=True)\n",
    "\n",
    "# top_n_features = feature_imp_df.loc[:,'feature_name'].tolist()\n",
    "# feature_imp_df.to_csv(os.path.join(output_dir_version,\"all_gain_feautures.csv\"))\n",
    "\n",
    "# top_n_features = feature_imp_df.iloc[0:20]\n",
    "# curr_df = curr_df[top_n_features]\n",
    "# ref_df = ref_df.drop([\"loan_id\"], axis=1)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# --- Define features to monitor ---\n",
    "cat_cols = ref_df.select_dtypes(include=[\"object\", \"category\"]).columns.tolist()\n",
    "num_cols = ref_df.select_dtypes(include=[\"int\", \"float\", \"number\"]).columns.tolist()\n",
    "\n",
    "\n",
    "results = []\n",
    "evaluation_date = date.today()\n",
    "\n",
    "# --- 1. Categorical Columns: Chi-Square Test ---\n",
    "for col in cat_cols:\n",
    "    try:\n",
    "        ref_counts = ref_df[col].value_counts()\n",
    "        cur_counts = curr_df[col].value_counts()\n",
    "\n",
    "        all_categories = set(ref_counts.index).union(set(cur_counts.index))\n",
    "        ref_aligned = [ref_counts.get(c, 0) for c in all_categories]\n",
    "        cur_aligned = [cur_counts.get(c, 0) for c in all_categories]\n",
    "\n",
    "        chi2, p, _, _ = chi2_contingency([ref_aligned, cur_aligned])\n",
    "        drift_status_cat = \"Drift\" if p < pvalue_threshold else \"Stable\"\n",
    "\n",
    "        results.append((\n",
    "            evaluation_date,\n",
    "            \"ff_bd\",\n",
    "            col,\n",
    "            \"categorical\",\n",
    "            \"chi_square\",\n",
    "            float(p),\n",
    "            drift_status_cat,\n",
    "            int(len(ref_df)),\n",
    "            int(len(curr_df)),\n",
    "            None,\n",
    "            datetime.now()\n",
    "        ))\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"‚ö†Ô∏è Skipped {col} due to error: {e}\")\n",
    "\n",
    "# --- 2. Numeric Columns: Mean & Std Deviation Comparison ---\n",
    "for col in num_cols:\n",
    "    try:\n",
    "        mean_ref, mean_cur = ref_df[col].mean(), curr_df[col].mean()\n",
    "        std_ref, std_cur = ref_df[col].std(), curr_df[col].std()\n",
    "\n",
    "        mean_diff = abs(mean_cur - mean_ref) / (abs(mean_ref) + 1e-6)\n",
    "        std_diff = abs(std_cur - std_ref) / (abs(std_ref) + 1e-6)\n",
    "\n",
    "        drift_status_num = \"Drift\" if (mean_diff > mean_diff_threshold or std_diff > std_diff_threshold) else \"Stable\"\n",
    "\n",
    "        results.append((\n",
    "            evaluation_date,\n",
    "            \"ff_bd\",\n",
    "            col,\n",
    "            \"numeric\",\n",
    "            \"mean_std\",\n",
    "            float(max(mean_diff, std_diff)),\n",
    "            drift_status_num,\n",
    "            int(len(ref_df)),\n",
    "            int(len(curr_df)),\n",
    "            None,\n",
    "            datetime.now()\n",
    "        ))\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"‚ö†Ô∏è Skipped {col} due to error: {e}\")\n",
    "\n",
    "# -------------------------------------------------------------\n",
    "# ‚≠ê NEW: GLOBAL DRIFT STATUS (Do not modify per-column results)\n",
    "# -------------------------------------------------------------\n",
    "drift_count = sum(1 for r in results if r[6] == \"Drift\")  # index 6 = drift_status\n",
    "drift_status = \"Drift\" if drift_count >= 20 else \"Stable\"\n",
    "\n",
    "print(f\"üîî Per-feature drift count = {drift_count}\")\n",
    "print(f\"üåê Global drift status = {drift_status}\")\n",
    "# -------------------------------------------------------------\n",
    "\n",
    "# --- Create DataFrame & Write to Delta Table ---\n",
    "from pyspark.sql.types import (\n",
    "    StructType,\n",
    "    StructField,\n",
    "    StringType,\n",
    "    IntegerType,\n",
    "    FloatType,\n",
    "    DateType,\n",
    "    DoubleType,\n",
    "    TimestampType\n",
    "\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "schema = StructType([\n",
    "    StructField(\"evaluation_date\", DateType(), True),\n",
    "    StructField(\"model_name\", StringType(), True),\n",
    "    StructField(\"feature_name\", StringType(), True),\n",
    "    StructField(\"feature_type\", StringType(), True),\n",
    "    StructField(\"metric_used\", StringType(), True),\n",
    "    StructField(\"metric_value\", DoubleType(), True),\n",
    "    StructField(\"drift_status\", StringType(), True),\n",
    "    StructField(\"ref_sample_size\", IntegerType(), True),\n",
    "    StructField(\"cur_sample_size\", IntegerType(), True),\n",
    "    StructField(\"comment\", StringType(), True),\n",
    "    StructField(\"created_at\", TimestampType(), True),\n",
    "])\n",
    "\n",
    "if results:\n",
    "    drift_df = spark.createDataFrame(results, schema)\n",
    "    drift_df = drift_df.withColumn(\"created_at\", F.current_timestamp())\n",
    "    drift_df = drift_df.drop(\"global_drift_status\")\n",
    "    drift_df = drift_df.withColumn(\"metric_value\", drift_df[\"metric_value\"].cast(\"double\"))\n",
    "    drift_df.write.format(\"delta\").mode(\"append\").saveAsTable(\"ispl_databricks.model_logs.data_drift_log\")\n",
    "    display(drift_df.printSchema())\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è No results to log ‚Äî check your reference and inference tables.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "18c8cdb1-b598-45e5-8948-da9b74c11f9c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "select * from ispl_databricks.model_logs.ff_bd_payload where execution_duration_ms is not null"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6568dcbd-b08c-40a4-8613-4cc2516d75c8",
     "showTitle": false,
     "tableResultSettingsMap": {
      "0": {
       "dataGridStateBlob": "{\"version\":1,\"tableState\":{\"columnPinning\":{\"left\":[\"#row_number#\"],\"right\":[]},\"columnSizing\":{},\"columnVisibility\":{}},\"settings\":{\"columns\":{}},\"syncTimestamp\":1765527510800}",
       "filterBlob": null,
       "queryPlanFiltersBlob": null,
       "tableResultIndex": 0
      }
     },
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "select * from ispl_databricks.model_logs.ff_bd_payload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "baf6ef16-3b9a-4e76-8f31-7af9020b01b2",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "select * from ispl_databricks.model_logs.data_drift_log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e0e5f4db-0325-4da9-8e7f-c95b5c531fcd",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "select * from ispl_databricks.model_logs.ff_bd_payload"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "015b2eb3-319d-4823-a2ca-c88c8635a9b9",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### dbutils.jobs.taskValues.set() stores these flags at job level."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e7a2dd5b-f0e9-4d64-862f-b4ce5383c2a9",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Persist overall drift status so downstream tasks can decide next actions\n",
    "dbutils.jobs.taskValues.set(\"drift_flag\", drift_status)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8e4d06d1-867c-471e-ad44-1cdcbe64ea14",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Persist schema drift result (column name/type mismatch)\n",
    "dbutils.jobs.taskValues.set(\"schema_drift\", schema_drift)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ceb174c9-eb54-433b-939c-a5abf66fc111",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "# Persist data quality drift result (business rule violations)\n",
    "dbutils.jobs.taskValues.set(\"dq_drift\", dq_drift)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9cc99876-fe68-4c62-8f8e-085483feacca",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "# Persist null value drift result (significant change in missing value patterns)\n",
    "dbutils.jobs.taskValues.set(\"null_value_drift\", null_value_drift )"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": {
    "hardware": {
     "accelerator": null,
     "gpuPoolId": null,
     "memory": null
    }
   },
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "4"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "mostRecentlyExecutedCommandWithImplicitDF": {
     "commandId": 884302934589424,
     "dataframes": [
      "_sqldf"
     ]
    },
    "pythonIndentUnit": 4
   },
   "notebookName": "Data Drift - ff_bd_updated",
   "widgets": {
    "mean_diff_threshold": {
     "currentValue": "0.2",
     "nuid": "cb2aa311-4bca-4d6b-a515-88eb36f0719f",
     "typedWidgetInfo": {
      "autoCreated": false,
      "defaultValue": "0.2",
      "label": "Mean Diff Threshold (Fraction)",
      "name": "mean_diff_threshold",
      "options": {
       "widgetDisplayType": "Text",
       "validationRegex": null
      },
      "parameterDataType": "String"
     },
     "widgetInfo": {
      "widgetType": "text",
      "defaultValue": "0.2",
      "label": "Mean Diff Threshold (Fraction)",
      "name": "mean_diff_threshold",
      "options": {
       "widgetType": "text",
       "autoCreated": null,
       "validationRegex": null
      }
     }
    },
    "model_name": {
     "currentValue": "loan_approval_model",
     "nuid": "bbb45e87-95ae-44cb-837b-c5664fc7ef3d",
     "typedWidgetInfo": {
      "autoCreated": false,
      "defaultValue": "ff_bd",
      "label": "Model Name",
      "name": "model_name",
      "options": {
       "widgetDisplayType": "Text",
       "validationRegex": null
      },
      "parameterDataType": "String"
     },
     "widgetInfo": {
      "widgetType": "text",
      "defaultValue": "ff_bd",
      "label": "Model Name",
      "name": "model_name",
      "options": {
       "widgetType": "text",
       "autoCreated": null,
       "validationRegex": null
      }
     }
    },
    "pvalue_threshold": {
     "currentValue": "0.05",
     "nuid": "0128567e-5f20-498b-8b12-57c706a39018",
     "typedWidgetInfo": {
      "autoCreated": false,
      "defaultValue": "0.05",
      "label": "Chi-Square p-value Threshold",
      "name": "pvalue_threshold",
      "options": {
       "widgetDisplayType": "Text",
       "validationRegex": null
      },
      "parameterDataType": "String"
     },
     "widgetInfo": {
      "widgetType": "text",
      "defaultValue": "0.05",
      "label": "Chi-Square p-value Threshold",
      "name": "pvalue_threshold",
      "options": {
       "widgetType": "text",
       "autoCreated": null,
       "validationRegex": null
      }
     }
    },
    "std_diff_threshold": {
     "currentValue": "0.3",
     "nuid": "8c9d407c-40cd-4be8-bfdc-565d6b64b06e",
     "typedWidgetInfo": {
      "autoCreated": false,
      "defaultValue": "0.3",
      "label": "Std Diff Threshold (Fraction)",
      "name": "std_diff_threshold",
      "options": {
       "widgetDisplayType": "Text",
       "validationRegex": null
      },
      "parameterDataType": "String"
     },
     "widgetInfo": {
      "widgetType": "text",
      "defaultValue": "0.3",
      "label": "Std Diff Threshold (Fraction)",
      "name": "std_diff_threshold",
      "options": {
       "widgetType": "text",
       "autoCreated": null,
       "validationRegex": null
      }
     }
    }
   }
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
